{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Attack Generator\n",
    "\n",
    "Based on: https://github.com/Trusted-AI/adversarial-robustness-toolbox/wiki/Get-Started#setup </p>\n",
    "- Docs: https://adversarial-robustness-toolbox.readthedocs.io/en/latest/index.html\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>Fwd Packet Length Std</th>\n",
       "      <th>...</th>\n",
       "      <th>min_seg_size_forward</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.837186</td>\n",
       "      <td>1.333333e-07</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.302326e-07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.002581</td>\n",
       "      <td>0.00101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.840070</td>\n",
       "      <td>1.016667e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>4.651163e-07</td>\n",
       "      <td>9.153974e-09</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.002581</td>\n",
       "      <td>0.00101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.840085</td>\n",
       "      <td>5.416666e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>4.651163e-07</td>\n",
       "      <td>9.153974e-09</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.002581</td>\n",
       "      <td>0.00101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.705516</td>\n",
       "      <td>3.916666e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>4.651163e-07</td>\n",
       "      <td>9.153974e-09</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.002581</td>\n",
       "      <td>0.00101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.837156</td>\n",
       "      <td>1.333333e-07</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.302326e-07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.002581</td>\n",
       "      <td>0.00101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Destination Port   Flow Duration   Total Fwd Packets  \\\n",
       "0           0.837186    1.333333e-07            0.000005   \n",
       "1           0.840070    1.016667e-06            0.000000   \n",
       "2           0.840085    5.416666e-07            0.000000   \n",
       "3           0.705516    3.916666e-07            0.000000   \n",
       "4           0.837156    1.333333e-07            0.000005   \n",
       "\n",
       "    Total Backward Packets  Total Length of Fwd Packets  \\\n",
       "0                 0.000000                 9.302326e-07   \n",
       "1                 0.000003                 4.651163e-07   \n",
       "2                 0.000003                 4.651163e-07   \n",
       "3                 0.000003                 4.651163e-07   \n",
       "4                 0.000000                 9.302326e-07   \n",
       "\n",
       "    Total Length of Bwd Packets   Fwd Packet Length Max  \\\n",
       "0                  0.000000e+00                0.000242   \n",
       "1                  9.153974e-09                0.000242   \n",
       "2                  9.153974e-09                0.000242   \n",
       "3                  9.153974e-09                0.000242   \n",
       "4                  0.000000e+00                0.000242   \n",
       "\n",
       "    Fwd Packet Length Min   Fwd Packet Length Mean   Fwd Packet Length Std  \\\n",
       "0                0.002581                  0.00101                     0.0   \n",
       "1                0.002581                  0.00101                     0.0   \n",
       "2                0.002581                  0.00101                     0.0   \n",
       "3                0.002581                  0.00101                     0.0   \n",
       "4                0.002581                  0.00101                     0.0   \n",
       "\n",
       "   ...   min_seg_size_forward  Active Mean   Active Std   Active Max  \\\n",
       "0  ...                    1.0          0.0          0.0          0.0   \n",
       "1  ...                    1.0          0.0          0.0          0.0   \n",
       "2  ...                    1.0          0.0          0.0          0.0   \n",
       "3  ...                    1.0          0.0          0.0          0.0   \n",
       "4  ...                    1.0          0.0          0.0          0.0   \n",
       "\n",
       "    Active Min  Idle Mean   Idle Std   Idle Max   Idle Min   Label  \n",
       "0          0.0        0.0        0.0        0.0        0.0       0  \n",
       "1          0.0        0.0        0.0        0.0        0.0       0  \n",
       "2          0.0        0.0        0.0        0.0        0.0       0  \n",
       "3          0.0        0.0        0.0        0.0        0.0       0  \n",
       "4          0.0        0.0        0.0        0.0        0.0       0  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # load data\n",
    "# import pandas as pd\n",
    "\n",
    "# # load dataset\n",
    "# df = pd.read_csv('../data/preprocessed/binary_min_max_combined.csv')\n",
    "# df.shape\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(848, 71)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # create smaller dataset\n",
    "# small_df = df.sample(frac=0.0003, random_state=10)\n",
    "# small_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         BENIGN  MALICIOUS\n",
      "468003    False       True\n",
      "1239319    True      False\n",
      "(636, 70) (212, 70)\n"
     ]
    }
   ],
   "source": [
    "# # split data\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X = small_df.drop(columns=[' Label'])\n",
    "# y = small_df[' Label']\n",
    "\n",
    "# y = pd.get_dummies(y)\n",
    "# y.columns = [\"BENIGN\", \"MALICIOUS\"]\n",
    "# print(y[:2])\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "# print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 70) (2000, 70) (8000, 2) (2000, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X_train = pd.read_csv(\"../CICIDS2017/train_test_split/X_train_proto.csv\")\n",
    "X_test = pd.read_csv(\"../CICIDS2017/train_test_split/X_test_proto.csv\")\n",
    "y_train = pd.read_csv(\"../CICIDS2017/train_test_split/y_train_proto.csv\")\n",
    "y_test = pd.read_csv(\"../CICIDS2017/train_test_split/y_test_proto.csv\")\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,550</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,530</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">310</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │         \u001b[38;5;34m3,550\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │         \u001b[38;5;34m1,530\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m310\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m22\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,238</span> (63.43 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,238\u001b[0m (63.43 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,412</span> (21.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,412\u001b[0m (21.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,826</span> (42.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m10,826\u001b[0m (42.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load model\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.models.load_model('../CICIDS2017/models/ids_dnn.keras')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      BENIGN       0.99      0.99      0.99      1619\n",
      "      ATTACK       0.94      0.97      0.95       381\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      2000\n",
      "   macro avg       0.97      0.98      0.97      2000\n",
      "weighted avg       0.98      0.98      0.98      2000\n",
      " samples avg       0.98      0.98      0.98      2000\n",
      "\n",
      "Accuracy : 98.20%\n"
     ]
    }
   ],
   "source": [
    "# convert model to ART -> needed for adversarial attacks\n",
    "from art.estimators.classification import TensorFlowV2Classifier\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define loss function\n",
    "loss_object = keras.losses.BinaryCrossentropy()\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "input_dim = X_train.shape[1] \n",
    "\n",
    "@tf.function\n",
    "def custom_train_step(model, x_batch, y_batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(x_batch, training=True)\n",
    "        loss = loss_object(y_batch, predictions)\n",
    "    \n",
    "    # Compute and apply gradients\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# KerasClassifier uses tf.keras.backend.placeholder, which has been removed in TensorFlow 2.10+.so we need to use TensorFlowV2Classifier\n",
    "classifier = TensorFlowV2Classifier(\n",
    "    model=model,\n",
    "    nb_classes=2,  # Binary classification (0 or 1)\n",
    "    input_shape=(input_dim,),  # Input shape\n",
    "    clip_values=(0, 1), # because of the min-max normalization\n",
    "    optimizer=optimizer, \n",
    "    loss_object=loss_object,\n",
    "    train_step=custom_train_step  # Use default training function\n",
    ")\n",
    "\n",
    "# print accuracy\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=['BENIGN', 'ATTACK']))\n",
    "print(f\"Accuracy : {accuracy_score(y_test, y_pred)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy -> needed for adversarial attacks\n",
    "X_test_np = X_test.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carlini & Wagner Attack - White Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64dad465c033443d84223e8dede1dd0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "Adversarial examples generated. Shape: (500, 70)\n"
     ]
    }
   ],
   "source": [
    "# from art.attacks.evasion import CarliniL2Method\n",
    "\n",
    "# # Create the C&W attack (non-targeted)\n",
    "# attack_cw = CarliniL2Method(classifier=classifier, confidence=0.0, targeted=False)\n",
    "\n",
    "# # Generate adversarial examples on the test set\n",
    "# X_test_adv_cw = attack_cw.generate(x=X_test_np)\n",
    "# print(f'Adversarial C&W examples generated. Shape: {X_test_adv_cw.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FGSM Attack - White Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial FGSM examples generated. Shape: (2000, 70)\n"
     ]
    }
   ],
   "source": [
    "from art.attacks.evasion import FastGradientMethod\n",
    "\n",
    "# Create FGSM attack\n",
    "attack_fgsm = FastGradientMethod(estimator=classifier, eps=0.5)  # ε tune this for stronger/weaker attacks: 0.01 weak, 0.1 balanced, 0.3-0.5 strong, 1 very strong\n",
    "# the higher the epsilon, the easier it will be detected\n",
    "\n",
    "# Generate adversarial examples\n",
    "X_test_adv_fgsm = attack_fgsm.generate(x=X_test_np)\n",
    "print(f'Adversarial FGSM examples generated. Shape: {X_test_adv_fgsm.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HopSkipJumpAttack - Black Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "307a6674b2ea48a29ff756e317686080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HopSkipJump:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial HopSkipJump examples generated. Shape: (2000, 70)\n"
     ]
    }
   ],
   "source": [
    "from art.attacks.evasion import HopSkipJump\n",
    "import numpy as np\n",
    "\n",
    "# Create HopSkipJump attack\n",
    "attack_hop_skip_jump = HopSkipJump(classifier=classifier, targeted=False, norm=2)\n",
    "\n",
    "# create target labels: [1, 0]\n",
    "target_labels = np.ones((X_test_np.shape[0], 2))\n",
    "target_labels[:, 0] = 1\n",
    "target_labels[:, 1] = 0\n",
    "print(target_labels[:2])\n",
    "\n",
    "\n",
    "# Generate adversarial examples\n",
    "X_test_adv_hop_skip_jump = attack_hop_skip_jump.generate(x=X_test_np)\n",
    "print(f'Adversarial HopSkipJump examples generated. Shape: {X_test_adv_hop_skip_jump.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# check for negative values in attacks\n",
    "print(np.any(X_test_adv_fgsm < 0))\n",
    "print(np.any(X_test_adv_hop_skip_jump < 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9798 - loss: 0.0483 \n",
      "Accuracy on clean examples: 98.20%\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7691 - loss: 377.8260  \n",
      "Accuracy on fgsm attack: 76.55%\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8243 - loss: 0.8233\n",
      "Accuracy on hop skip jump attack: 80.95%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on adversarial examples\n",
    "loss, accuracy = model.evaluate(X_test_np, y_test)\n",
    "print(f'Accuracy on clean examples: {accuracy * 100:.2f}%')\n",
    "\n",
    "#loss_adv, accuracy_adv = model.evaluate(X_test_adv_cw, y_test)\n",
    "#print(f'Accuracy on c&w attack: {accuracy_adv * 100:.2f}%')\n",
    "\n",
    "loss_adv_fgsm, accuracy_adv_fgsm = model.evaluate(X_test_adv_fgsm, y_test)\n",
    "print(f'Accuracy on fgsm attack: {accuracy_adv_fgsm * 100:.2f}%')\n",
    "\n",
    "loss_adv_hop_skip_jump, accuracy_adv_hop_skip_jump = model.evaluate(X_test_adv_hop_skip_jump, y_test)\n",
    "print(f'Accuracy on hop skip jump attack: {accuracy_adv_hop_skip_jump * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step\n",
      "Normal Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      BENIGN       0.99      0.99      0.99      1619\n",
      "      ATTACK       0.94      0.97      0.95       381\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      2000\n",
      "   macro avg       0.97      0.98      0.97      2000\n",
      "weighted avg       0.98      0.98      0.98      2000\n",
      " samples avg       0.98      0.98      0.98      2000\n",
      "\n",
      "FGSM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      BENIGN       0.80      0.94      0.87      1619\n",
      "      ATTACK       0.08      0.02      0.04       381\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      2000\n",
      "   macro avg       0.44      0.48      0.45      2000\n",
      "weighted avg       0.67      0.77      0.71      2000\n",
      " samples avg       0.77      0.77      0.77      2000\n",
      "\n",
      "Hop Skip Jump Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      BENIGN       0.81      1.00      0.89      1619\n",
      "      ATTACK       0.00      0.00      0.00       381\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      2000\n",
      "   macro avg       0.40      0.50      0.45      2000\n",
      "weighted avg       0.66      0.81      0.72      2000\n",
      " samples avg       0.81      0.81      0.81      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felix/Documents/Uni/Master Arbeit/Python/xai-assisted-intrusion-detection-system/.env/lib64/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "#y_pred_adv_cw = model.predict(X_test_adv_cw)\n",
    "#y_pred_adv_cw = (y_pred_adv_cw > 0.5)\n",
    "y_pred_adv_fgsm = model.predict(X_test_adv_fgsm)\n",
    "y_pred_adv_fgsm = (y_pred_adv_fgsm > 0.5)\n",
    "y_pred_adv_hop_skip_jump = model.predict(X_test_adv_hop_skip_jump)\n",
    "y_pred_adv_hop_skip_jump = (y_pred_adv_hop_skip_jump > 0.5)\n",
    "\n",
    "print(\"Normal Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['BENIGN', 'ATTACK']))\n",
    "#print(\"C&W Classification Report:\")\n",
    "#print(classification_report(y_test, y_pred_adv_cw, target_names=['BENIGN', 'ATTACK']))\n",
    "print(\"FGSM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_adv_fgsm, target_names=['BENIGN', 'ATTACK']))\n",
    "print(\"Hop Skip Jump Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_adv_hop_skip_jump, target_names=['BENIGN', 'ATTACK']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal:\n",
      "Accuracy: 98.20%\n",
      "Precision: 99.19%\n",
      "Recall: 98.58%\n",
      "F1-Score: 98.88%\n",
      "FGSM:\n",
      "Accuracy: 76.55%\n",
      "Precision: 80.36%\n",
      "Recall: 94.01%\n",
      "F1-Score: 86.65%\n",
      "Hop Skip Jump:\n",
      "Accuracy: 80.95%\n",
      "Precision: 80.95%\n",
      "Recall: 100.00%\n",
      "F1-Score: 89.47%\n"
     ]
    }
   ],
   "source": [
    "# show accuracy, precision, recall, f1-score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# convert to binary \n",
    "y_test_binary = np.array(y_test).argmin(axis=1)\n",
    "y_pred_binary = np.array(y_pred).argmin(axis=1)\n",
    "y_pred_adv_fgsm_binary = np.array(y_pred_adv_fgsm).argmin(axis=1)\n",
    "y_pred_adv_hop_skip_jump_binary = np.array(y_pred_adv_hop_skip_jump).argmin(axis=1)\n",
    "y_pred_hop_skip_jump_binary = np.array(y_pred_adv_hop_skip_jump).argmin(axis=1)\n",
    "\n",
    "print(\"Normal:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_binary, y_pred_binary)*100:.2f}%\")\n",
    "print(f\"Precision: {precision_score(y_test_binary, y_pred_binary)*100:.2f}%\")\n",
    "print(f\"Recall: {recall_score(y_test_binary, y_pred_binary)*100:.2f}%\")\n",
    "print(f\"F1-Score: {f1_score(y_test_binary, y_pred_binary)*100:.2f}%\")\n",
    "\n",
    "print(\"FGSM:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_binary, y_pred_adv_fgsm_binary)*100:.2f}%\")\n",
    "print(f\"Precision: {precision_score(y_test_binary, y_pred_adv_fgsm_binary)*100:.2f}%\")\n",
    "print(f\"Recall: {recall_score(y_test_binary, y_pred_adv_fgsm_binary)*100:.2f}%\")\n",
    "print(f\"F1-Score: {f1_score(y_test_binary, y_pred_adv_fgsm_binary)*100:.2f}%\")\n",
    "\n",
    "print(\"Hop Skip Jump:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_binary, y_pred_adv_hop_skip_jump_binary)*100:.2f}%\")\n",
    "print(f\"Precision: {precision_score(y_test_binary, y_pred_adv_hop_skip_jump_binary)*100:.2f}%\")\n",
    "print(f\"Recall: {recall_score(y_test_binary, y_pred_adv_hop_skip_jump_binary)*100:.2f}%\")\n",
    "print(f\"F1-Score: {f1_score(y_test_binary, y_pred_adv_hop_skip_jump_binary)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Destination Port   Flow Duration   Total Fwd Packets  \\\n",
      "0           0.085107             0.0                 0.0   \n",
      "1           0.501221             0.0                 0.0   \n",
      "\n",
      "    Total Backward Packets  Total Length of Fwd Packets  \\\n",
      "0                      0.0                          0.0   \n",
      "1                      0.0                          0.5   \n",
      "\n",
      "    Total Length of Bwd Packets   Fwd Packet Length Max  \\\n",
      "0                           0.0                0.500242   \n",
      "1                           0.5                0.500000   \n",
      "\n",
      "    Fwd Packet Length Min   Fwd Packet Length Mean   Fwd Packet Length Std  \\\n",
      "0                0.502581                  0.50101                     0.5   \n",
      "1                0.500000                  0.50000                     0.5   \n",
      "\n",
      "   ...   act_data_pkt_fwd   min_seg_size_forward  Active Mean   Active Std  \\\n",
      "0  ...                0.0                    1.0          0.0          0.0   \n",
      "1  ...                0.0                    0.5          0.5          0.5   \n",
      "\n",
      "    Active Max   Active Min  Idle Mean   Idle Std   Idle Max   Idle Min  \n",
      "0          0.0          0.0   0.591667        0.0   0.591667   0.591667  \n",
      "1          0.5          0.5   0.500000        0.5   0.000000   0.500000  \n",
      "\n",
      "[2 rows x 70 columns]\n",
      "    Destination Port   Flow Duration   Total Fwd Packets  \\\n",
      "0           0.585107        0.092050            0.000000   \n",
      "1           0.001221        0.001276            0.000009   \n",
      "\n",
      "    Total Backward Packets  Total Length of Fwd Packets  \\\n",
      "0                 0.000017                 4.651163e-07   \n",
      "1                 0.000000                 0.000000e+00   \n",
      "\n",
      "    Total Length of Bwd Packets   Fwd Packet Length Max  \\\n",
      "0                  4.576987e-08                0.000242   \n",
      "1                  0.000000e+00                0.000000   \n",
      "\n",
      "    Fwd Packet Length Min   Fwd Packet Length Mean   Fwd Packet Length Std  \\\n",
      "0                0.002581                  0.00101                     0.0   \n",
      "1                0.000000                  0.00000                     0.0   \n",
      "\n",
      "   ...   act_data_pkt_fwd   min_seg_size_forward  Active Mean   Active Std  \\\n",
      "0  ...                0.0                    1.0     0.000342          0.0   \n",
      "1  ...                0.0                    1.0     0.000000          0.0   \n",
      "\n",
      "    Active Max   Active Min  Idle Mean   Idle Std   Idle Max   Idle Min  \n",
      "0     0.000342     0.000342   0.091667        0.0   0.091667   0.091667  \n",
      "1     0.000000     0.000000   0.000000        0.0   0.000000   0.000000  \n",
      "\n",
      "[2 rows x 70 columns]\n",
      "         0         1         2         3             4             5   \\\n",
      "0  0.585107  0.092050  0.000000  0.000017  4.651163e-07  4.576987e-08   \n",
      "1  0.001221  0.001276  0.000009  0.000000  0.000000e+00  0.000000e+00   \n",
      "\n",
      "         6         7        8    9   ...   60   61        62   63        64  \\\n",
      "0  0.000242  0.002581  0.00101  0.0  ...  0.0  1.0  0.000342  0.0  0.000342   \n",
      "1  0.000000  0.000000  0.00000  0.0  ...  0.0  1.0  0.000000  0.0  0.000000   \n",
      "\n",
      "         65        66   67        68        69  \n",
      "0  0.000342  0.091667  0.0  0.091667  0.091667  \n",
      "1  0.000000  0.000000  0.0  0.000000  0.000000  \n",
      "\n",
      "[2 rows x 70 columns]\n"
     ]
    }
   ],
   "source": [
    "#adv_cw_df = pd.DataFrame(X_test_adv_cw)\n",
    "# set column names\n",
    "#adv_cw_df.columns = X_test.columns\n",
    "#print(adv_cw_df.head(2))\n",
    "\n",
    "adv_fgsm_df = pd.DataFrame(X_test_adv_fgsm)\n",
    "# set column names\n",
    "adv_fgsm_df.columns = X_test.columns\n",
    "print(adv_fgsm_df.head(2))\n",
    "\n",
    "adv_hop_skip_jump_df = pd.DataFrame(X_test_adv_hop_skip_jump)\n",
    "# set column names\n",
    "adv_hop_skip_jump_df.columns = X_test.columns\n",
    "print(adv_hop_skip_jump_df.head(2))\n",
    "\n",
    "norm_df = pd.DataFrame(X_test_np)\n",
    "print(norm_df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Adversarial Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the adversarial examples\n",
    "#adv_cw_df.to_csv(\"../CICIDS2017/adversarial_samples/X_test_small_adv_cw.csv\", index=False)\n",
    "adv_fgsm_df.to_csv(\"../CICIDS2017/adversarial_samples/X_test_adv_fgsm_proto.csv\", index=False)\n",
    "adv_hop_skip_jump_df.to_csv(\"../CICIDS2017/adversarial_samples/X_test_adv_hsj_proto.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
