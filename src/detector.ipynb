{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototype - Adversarial Detector\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Required Model & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,550</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,530</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">310</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │         \u001b[38;5;34m3,550\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │         \u001b[38;5;34m1,530\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m310\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m22\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,238</span> (63.43 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,238\u001b[0m (63.43 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,412</span> (21.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,412\u001b[0m (21.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,826</span> (42.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m10,826\u001b[0m (42.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load model\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.models.load_model('../CICIDS2017/models/ids_dnn.keras')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 70) (2000, 2)\n"
     ]
    }
   ],
   "source": [
    "# load data split\n",
    "import pandas as pd\n",
    "\n",
    "X_test = pd.read_csv(\"../CICIDS2017/train_test_split/X_test_proto.csv\")\n",
    "y_test = pd.read_csv(\"../CICIDS2017/train_test_split/y_test_proto.csv\")\n",
    "\n",
    "print(X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load adversarail samples\n",
    "\n",
    "X_test_adv_fgsm = pd.read_csv(\"../CICIDS2017/adversarial_samples/X_test_adv_fgsm_proto.csv\")\n",
    "X_test_adv_hsj = pd.read_csv(\"../CICIDS2017/adversarial_samples/X_test_adv_hsj_proto.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 70)\n",
      "(2000, 70)\n",
      "(2000, 70)\n"
     ]
    }
   ],
   "source": [
    "# load explanations\n",
    "\n",
    "shap_values_df = pd.read_csv(\"../CICIDS2017/shap_values/shap_values_proto.csv\")\n",
    "print(shap_values_df.shape)\n",
    "adv_shap_values_fgsm_df = pd.read_csv(\"../CICIDS2017/shap_values/adv_shap_values_fgsm_proto.csv\")\n",
    "print(adv_shap_values_fgsm_df.shape)\n",
    "adv_shap_values_hsj_df = pd.read_csv(\"../CICIDS2017/shap_values/adv_shap_values_hsj_proto.csv\")\n",
    "print(adv_shap_values_hsj_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## First Stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step\n",
      "Accuracy on test set: 98.20%\n",
      "Accuracy on adversarial samples (FGSM): 76.55%\n",
      "Accuracy on adversarial samples (HSJ): 80.95%\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_adv_fgsm = model.predict(X_test_adv_fgsm)\n",
    "y_pred_adv_hsj = model.predict(X_test_adv_hsj)\n",
    "\n",
    "# evaluate model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(f\"Accuracy on test set: {accuracy_score(y_test, y_pred.round())*100:.2f}%\")\n",
    "print(f\"Accuracy on adversarial samples (FGSM): {accuracy_score(y_test, y_pred_adv_fgsm.round())*100:.2f}%\")\n",
    "print(f\"Accuracy on adversarial samples (HSJ): {accuracy_score(y_test, y_pred_adv_hsj.round())*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Benign Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# convert to binary, 1 == benign, 0 == malicious -> easier to work on\n",
    "y_test_binary = np.array(y_test).argmin(axis=1)\n",
    "y_pred_binary = y_pred.argmin(axis=1)\n",
    "adv_fgsm_pred_binary = y_pred_adv_fgsm.argmin(axis=1)\n",
    "adv_hsj_pred_binary = y_pred_adv_hsj.argmin(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Labels:                           [1 1 1 1 1 1 1 1 1 0]\n",
      "Predicted Labels:                         [1 1 1 1 1 1 1 1 1 0]\n",
      "Correctly classified benign samples:      [ 0  1  2  3  4  5  6  7  8 10]\n",
      "Predicted Labels (FGSM):                  [1 1 1 1 1 0 1 1 1 1]\n",
      "Adversarial samples classified as benign: [ 0  1  2  3  4  6  7  8  9 10]\n",
      "Predicted Labels (HSJ):                   [1 1 1 1 1 1 1 1 1 1]\n",
      "Adversarial samples classified as benign: [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Correct Labels:                           {y_test_binary[:10]}\")\n",
    "\n",
    "# find indices of correctly classified benign samples\n",
    "correct_benign_classified_indices = np.where((y_test_binary == 1) & (y_pred_binary == 1))[0]\n",
    "print(f\"Predicted Labels:                         {y_pred_binary[:10]}\")\n",
    "print(f\"Correctly classified benign samples:      {correct_benign_classified_indices[:10]}\")\n",
    "\n",
    "# find indices of adversarial samples that were classified as benign\n",
    "# FGSM\n",
    "adv_fgsm_benign_indices = np.where(adv_fgsm_pred_binary == 1)[0]\n",
    "print(f\"Predicted Labels (FGSM):                  {adv_fgsm_pred_binary[:10]}\")\n",
    "print(f\"Adversarial samples classified as benign: {adv_fgsm_benign_indices[:10]}\")\n",
    "# HSJ\n",
    "adv_hsj_benign_indices = np.where(adv_hsj_pred_binary == 1)[0]\n",
    "print(f\"Predicted Labels (HSJ):                   {adv_hsj_pred_binary[:10]}\")\n",
    "print(f\"Adversarial samples classified as benign: {adv_hsj_benign_indices[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Build Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly classified benign samples:\n",
      "(1596, 70)\n",
      "Adversarial samples classified as benign (FGSM):\n",
      "(1894, 70)\n",
      "Adversarial samples classified as benign (HSJ):\n",
      "(2000, 70)\n",
      "X:\n",
      "(5490, 70)\n",
      "y:\n",
      "(1596, 2) (3894, 2)\n",
      "[1 0] [0 1]\n",
      "(5490, 2)\n"
     ]
    }
   ],
   "source": [
    "# get shap values for correctly classified benign samples\n",
    "print(\"Correctly classified benign samples:\")\n",
    "shap_values_benign_df = shap_values_df.iloc[correct_benign_classified_indices]\n",
    "print(shap_values_benign_df.shape)\n",
    "\n",
    "# get shap values for adversarial samples classified as benign\n",
    "# FGSM\n",
    "print(\"Adversarial samples classified as benign (FGSM):\")\n",
    "adv_shap_values_fgsm_benign_df = adv_shap_values_fgsm_df.iloc[adv_fgsm_benign_indices]\n",
    "print(adv_shap_values_fgsm_benign_df.shape)\n",
    "# HSJ\n",
    "print(\"Adversarial samples classified as benign (HSJ):\")\n",
    "adv_shap_values_hsj_benign_df = adv_shap_values_hsj_df.iloc[adv_hsj_benign_indices]\n",
    "print(adv_shap_values_hsj_benign_df.shape)\n",
    "\n",
    "# build X\n",
    "print(\"X:\")\n",
    "X = pd.concat([shap_values_benign_df, adv_shap_values_fgsm_benign_df, adv_shap_values_hsj_benign_df], axis=0)\n",
    "print(X.shape)\n",
    "\n",
    "# build y \n",
    "# normal: [1, 0], adv: [0, 1]\n",
    "print(\"y:\")\n",
    "y_normal = np.array([[1, 0]] * shap_values_benign_df.shape[0])\n",
    "y_adv = np.array([[0, 1]] * (adv_shap_values_fgsm_benign_df.shape[0] + adv_shap_values_hsj_benign_df.shape[0]))\n",
    "print(y_normal.shape, y_adv.shape)\n",
    "print(y_normal[0], y_adv[0])\n",
    "y = np.concatenate([y_normal, y_adv], axis=0)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: maybe not needed -> random_state in train-test-split\n",
    "# shuffle both sets in the same way\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "X, y = shuffle(X, y, random_state=187)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train/Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4117, 70) (1373, 70) (4117, 2) (1373, 2)\n"
     ]
    }
   ],
   "source": [
    "# spit data into train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_detector, X_test_detector, y_train_detector, y_test_detector = train_test_split(X, y, test_size=0.25, random_state=187)\n",
    "print(X_train_detector.shape, X_test_detector.shape, y_train_detector.shape, y_test_detector.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DNN model from tensorflow\n",
    "import setuptools.dist # needed to avoid error\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# keras model for handling one hot encoded labels -> needed for attack creation\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(50, input_dim=X_train_detector.shape[1], activation='relu')) # hidden layer\n",
    "model.add(keras.layers.Dense(30, activation='relu')) # hidden layer\n",
    "model.add(keras.layers.Dense(10, activation='relu')) # hidden layer\n",
    "model.add(keras.layers.Dense(y_train_detector.shape[1], activation='softmax'))  # Output layer with softmax for one-hot encoding\n",
    "\n",
    "# set learning rate\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7005 - loss: 0.6769 - val_accuracy: 0.6824 - val_loss: 0.6298\n",
      "Epoch 2/10\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7180 - loss: 0.5960 - val_accuracy: 0.6824 - val_loss: 0.5909\n",
      "Epoch 3/10\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7169 - loss: 0.5474 - val_accuracy: 0.6824 - val_loss: 0.5324\n",
      "Epoch 4/10\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7229 - loss: 0.4747 - val_accuracy: 0.6846 - val_loss: 0.4217\n",
      "Epoch 5/10\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7584 - loss: 0.3712 - val_accuracy: 0.9170 - val_loss: 0.3036\n",
      "Epoch 6/10\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9358 - loss: 0.2589 - val_accuracy: 0.9621 - val_loss: 0.2154\n",
      "Epoch 7/10\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9821 - loss: 0.1785 - val_accuracy: 0.9854 - val_loss: 0.1249\n",
      "Epoch 8/10\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9889 - loss: 0.1004 - val_accuracy: 0.9891 - val_loss: 0.0708\n",
      "Epoch 9/10\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9945 - loss: 0.0521 - val_accuracy: 0.9942 - val_loss: 0.0461\n",
      "Epoch 10/10\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.0364 - val_accuracy: 0.9964 - val_loss: 0.0357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f6510720ef0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the keras model on the dataset\n",
    "model.fit(X_train_detector, y_train_detector, validation_data=(X_test_detector, y_test_detector), epochs=10, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "(1373,) (1373,)\n"
     ]
    }
   ],
   "source": [
    "y_pred_detector = model.predict(X_test_detector)\n",
    "y_pred_detector = (y_pred_detector > 0.5)\n",
    "\n",
    "y_test_detector_binary = np.array(y_test_detector).argmin(axis=1)\n",
    "y_pred_detector_binary = y_pred_detector.argmin(axis=1)\n",
    "print(y_test_detector_binary.shape, y_pred_detector_binary.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Accuracy: 99.64%\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "            NORMAL       1.00      0.99      0.99       436\n",
      "ADVERSARIAL ATTACK       1.00      1.00      1.00       937\n",
      "\n",
      "         micro avg       1.00      1.00      1.00      1373\n",
      "         macro avg       1.00      1.00      1.00      1373\n",
      "      weighted avg       1.00      1.00      1.00      1373\n",
      "       samples avg       1.00      1.00      1.00      1373\n",
      "\n",
      "True Negative Rate: 99.79%\n",
      "False Positive Rate: 0.21%\n",
      "True Positive Rate: 99.31%\n",
      "False Negative Rate: 0.69%\n"
     ]
    }
   ],
   "source": [
    "# print accuracy, precision, recall and f1-score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# print accuracy\n",
    "print(f\"Global Accuracy: {accuracy_score(y_test_detector, y_pred_detector)*100:.2f}%\")\n",
    "\n",
    "\n",
    "# precision, recall, f1-score\n",
    "print(classification_report(y_test_detector, y_pred_detector, target_names=['NORMAL', 'ADVERSARIAL ATTACK']))\n",
    "\n",
    "# print true positive rate, false positive rate, true negative rate, false negative rate\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test_detector_binary, y_pred_detector_binary).ravel()\n",
    "print(f\"True Negative Rate: {tn/(tn+fp)*100:.2f}%\")\n",
    "print(f\"False Positive Rate: {fp/(tn+fp)*100:.2f}%\")\n",
    "print(f\"True Positive Rate: {tp/(tp+fn)*100:.2f}%\")\n",
    "print(f\"False Negative Rate: {fn/(tp+fn)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Positives: 2\n",
      "False Negatives: 3\n"
     ]
    }
   ],
   "source": [
    "# show number of false positives and false negatives\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[155 664]\n",
      "[774 891 899]\n"
     ]
    }
   ],
   "source": [
    "# show false positive samples\n",
    "fp_indices = np.where((y_test_detector_binary == 0) & (y_pred_detector_binary == 1))[0]\n",
    "print(fp_indices)\n",
    "# show false negative samples\n",
    "fn_indices = np.where((y_test_detector_binary == 1) & (y_pred_detector_binary == 0))[0]\n",
    "print(fn_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PermutationExplainer explainer:  13%|█▎        | 172/1373 [00:13<01:18, 15.22it/s]"
     ]
    }
   ],
   "source": [
    "import shap \n",
    "\n",
    "# init shap explainer\n",
    "explainer = shap.Explainer(model, X_test_detector, feature_names=X_test_detector.columns)\n",
    "shap_values = explainer(X_test_detector)\n",
    "\n",
    "print(shap_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert shap values to correct format\n",
    "print(shap_values.shape) # one shap value per feature per sample per class\n",
    "shap_values = shap_values[:, :, 0] # 1 == Benign, 0 == Malicious\n",
    "print(shap_values.shape) # one shap value per feature per sample"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
