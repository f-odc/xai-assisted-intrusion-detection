{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototype: ny\n",
    "\n",
    "| Properties      | Data    |\n",
    "|---------------|-----------|\n",
    "| *Dataset* | `NSL-KDD` |\n",
    "| *Labels* | `ALL` |\n",
    "| *Normalization* | `Min-Max` |\n",
    "| *Sample Size* | `50.000`|\n",
    "| *Adversarial Attack* | `FGSM & C&W & JSMA & PGD` |\n",
    "| *Explanations* | `SHAP` |\n",
    "| *Detector* | `Detect Attacks and Misclassified Samples` |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Has to be run first alone!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To import modules from the functions directory\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Building NSL-KDD dataset --\n",
      "--- Extracting labels ---\n",
      " Label\n",
      "normal     77054\n",
      "neptune    45871\n",
      "Name: count, dtype: int64\n",
      "(122925, 42)\n",
      "   duration  protocol_type  service  flag  src_bytes  dst_bytes  land  \\\n",
      "0         0              1       20     9        491          0     0   \n",
      "1         0              2       44     9        146          0     0   \n",
      "\n",
      "   wrong_fragment  urgent  hot  ...  dst_host_srv_count  \\\n",
      "0               0       0    0  ...                  25   \n",
      "1               0       0    0  ...                   1   \n",
      "\n",
      "   dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
      "0                    0.17                    0.03   \n",
      "1                    0.00                    0.60   \n",
      "\n",
      "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
      "0                         0.17                          0.0   \n",
      "1                         0.88                          0.0   \n",
      "\n",
      "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
      "0                   0.0                       0.0                  0.05   \n",
      "1                   0.0                       0.0                  0.00   \n",
      "\n",
      "   dst_host_srv_rerror_rate   Label  \n",
      "0                       0.0  normal  \n",
      "1                       0.0  normal  \n",
      "\n",
      "[2 rows x 42 columns]\n",
      "-- Generating normalizer --\n",
      "--- Splitting labels and features ---\n",
      "Zero Columns: ['num_outbound_cmds']\n",
      "-- Preprocessing data --\n",
      "--- Splitting labels and features ---\n",
      "--- Encoding labels as binary one-hot values ---\n",
      "--- Sampling balanced data ---\n",
      "Sample to shape: (50000, 40)\n",
      "--- Normalizing features using MinMaxScaler ---\n",
      "Generate Features | Indices: Index([95104, 13634, 84604, 104469, 30357], dtype='int64')... | Shape: (50000, 40)\n",
      "Generate Labels | Indices: Index([95104, 13634, 84604, 104469, 30357], dtype='int64')... | Shape: (50000, 2)\n",
      "BENIGN  ATTACK\n",
      "False   True      25000\n",
      "True    False     25000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import functions.data_preprocessing as dp\n",
    "import importlib\n",
    "importlib.reload(dp)\n",
    "\n",
    "encoding_type = 0 # binary encoding\n",
    "norm_type = 0 # min-max normalization\n",
    "sample_size = 25000 # sample size for each label -> 2 x sample_size = total samples\n",
    "\n",
    "dataset = dp.build_nsl_kdd_dataset()\n",
    "print(dataset.shape)\n",
    "print(dataset.head(2))\n",
    "\n",
    "normalizer, zero_columns = dp.generate_normalizer(dataset, norm_type)\n",
    "\n",
    "\n",
    "feature_df, label_df, used_indices = dp.preprocess_data(dataset, encoding_type, normalizer, zero_columns, sample_size=sample_size, random_sample_state=42)\n",
    "print(f\"Generate Features | Indices: {feature_df.index[:5]}... | Shape: {feature_df.shape}\")\n",
    "print(f\"Generate Labels | Indices: {label_df.index[:5]}... | Shape: {label_df.shape}\")\n",
    "print(label_df.value_counts()) # -> will first show [0, 1] then [1, 0] if label number is equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(148517,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " Label\n",
       "normal             77054\n",
       "neptune            45871\n",
       "satan               4368\n",
       "ipsweep             3740\n",
       "smurf               3311\n",
       "portsweep           3088\n",
       "nmap                1566\n",
       "back                1315\n",
       "guess_passwd        1284\n",
       "mscan                996\n",
       "warezmaster          964\n",
       "teardrop             904\n",
       "warezclient          890\n",
       "apache2              737\n",
       "processtable         685\n",
       "snmpguess            331\n",
       "saint                319\n",
       "mailbomb             293\n",
       "pod                  242\n",
       "snmpgetattack        178\n",
       "httptunnel           133\n",
       "buffer_overflow       50\n",
       "land                  25\n",
       "multihop              25\n",
       "rootkit               23\n",
       "named                 17\n",
       "ps                    15\n",
       "sendmail              14\n",
       "xterm                 13\n",
       "imap                  12\n",
       "ftp_write             11\n",
       "loadmodule            11\n",
       "xlock                  9\n",
       "phf                    6\n",
       "perl                   5\n",
       "xsnoop                 4\n",
       "spy                    2\n",
       "worm                   2\n",
       "sqlattack              2\n",
       "udpstorm               2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataset[' Label'].shape)\n",
    "dataset[' Label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 40) (5000, 40) (45000, 2) (5000, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_df, label_df, test_size=0.1, random_state=42)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 933us/step - accuracy: 0.8985 - loss: 0.2619 - val_accuracy: 0.9626 - val_loss: 0.1059\n",
      "Epoch 2/20\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 801us/step - accuracy: 0.9598 - loss: 0.1033 - val_accuracy: 0.9716 - val_loss: 0.0794\n",
      "Epoch 3/20\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 811us/step - accuracy: 0.9685 - loss: 0.0813 - val_accuracy: 0.9764 - val_loss: 0.0683\n",
      "Epoch 4/20\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 846us/step - accuracy: 0.9729 - loss: 0.0699 - val_accuracy: 0.9788 - val_loss: 0.0626\n",
      "Epoch 5/20\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 797us/step - accuracy: 0.9764 - loss: 0.0625 - val_accuracy: 0.9808 - val_loss: 0.0604\n",
      "Epoch 6/20\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 792us/step - accuracy: 0.9786 - loss: 0.0576 - val_accuracy: 0.9811 - val_loss: 0.0577\n",
      "Epoch 7/20\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 788us/step - accuracy: 0.9797 - loss: 0.0535 - val_accuracy: 0.9820 - val_loss: 0.0549\n",
      "Epoch 8/20\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 811us/step - accuracy: 0.9813 - loss: 0.0505 - val_accuracy: 0.9826 - val_loss: 0.0540\n",
      "Epoch 9/20\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 807us/step - accuracy: 0.9825 - loss: 0.0484 - val_accuracy: 0.9824 - val_loss: 0.0532\n",
      "Epoch 10/20\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 787us/step - accuracy: 0.9833 - loss: 0.0459 - val_accuracy: 0.9828 - val_loss: 0.0524\n",
      "Epoch 11/20\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 812us/step - accuracy: 0.9844 - loss: 0.0447 - val_accuracy: 0.9823 - val_loss: 0.0519\n",
      "Epoch 12/20\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 796us/step - accuracy: 0.9846 - loss: 0.0435 - val_accuracy: 0.9830 - val_loss: 0.0507\n",
      "Epoch 13/20\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 793us/step - accuracy: 0.9849 - loss: 0.0423 - val_accuracy: 0.9833 - val_loss: 0.0495\n",
      "Epoch 14/20\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 804us/step - accuracy: 0.9852 - loss: 0.0416 - val_accuracy: 0.9834 - val_loss: 0.0497\n",
      "Epoch 15/20\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 803us/step - accuracy: 0.9851 - loss: 0.0404 - val_accuracy: 0.9842 - val_loss: 0.0498\n",
      "Epoch 16/20\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 807us/step - accuracy: 0.9855 - loss: 0.0394 - val_accuracy: 0.9846 - val_loss: 0.0506\n",
      "Epoch 17/20\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 804us/step - accuracy: 0.9857 - loss: 0.0392 - val_accuracy: 0.9830 - val_loss: 0.0515\n",
      "Epoch 18/20\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 818us/step - accuracy: 0.9861 - loss: 0.0382 - val_accuracy: 0.9827 - val_loss: 0.0531\n",
      "Epoch 19/20\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 798us/step - accuracy: 0.9865 - loss: 0.0378 - val_accuracy: 0.9830 - val_loss: 0.0535\n",
      "Epoch 20/20\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 808us/step - accuracy: 0.9864 - loss: 0.0369 - val_accuracy: 0.9822 - val_loss: 0.0535\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step\n",
      "Global Accuracy: 98.62%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ATTACK     0.9882    0.9838    0.9860      2472\n",
      "      BENIGN     0.9842    0.9885    0.9864      2528\n",
      "\n",
      "    accuracy                         0.9862      5000\n",
      "   macro avg     0.9862    0.9862    0.9862      5000\n",
      "weighted avg     0.9862    0.9862    0.9862      5000\n",
      "\n",
      "\u001b[1m   1/1407\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 16ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 15:01:21.955083: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 368us/step\n",
      "Predictions on Normal Data | Indices: Index([35100, 44022, 12737, 26214, 20883], dtype='int64')... | Shape: (45000, 2)\n"
     ]
    }
   ],
   "source": [
    "import functions.intrusion_detection_system as ids\n",
    "import importlib\n",
    "importlib.reload(ids)\n",
    "\n",
    "# TODO: build ids with complete dataset\n",
    "# X_train_all, y_train_all, _ = dp.preprocess_data(dataset, encoding_type, normalizer, zero_columns, random_sample_state=42)\n",
    "# print(y_train_all.value_counts())\n",
    "# X_train_all, X_test_all, y_train_all, y_test_all = train_test_split(X_train_all, y_train_all, test_size=0.2, random_state=42)\n",
    "# print(X_train_all.shape, X_test_all.shape, y_train_all.shape, y_test_all.shape)\n",
    "\n",
    "# build ids and evaluate it on test data\n",
    "ids_model = ids.build_intrusion_detection_system(X_train, y_train, X_test, y_test)\n",
    "# store prediction from X_train\n",
    "y_pred = ids.predict(ids_model, X_train, columns=y_train.columns)\n",
    "print(f\"Predictions on Normal Data | Indices: {y_pred.index[:5]}... | Shape: {y_pred.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Adversarial Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Data: (9000, 40) | CW Data: (9000, 40) | FGSM Data: (9000, 40) | JSMA Data: (9000, 40) | PGD Data: (9000, 40)\n",
      "Adversarial FGSM examples generated. Shape: (9000, 40)\n",
      "Create FGSM Adversarial Attack | Indices: Index([58311, 7703, 25104, 22457, 103581], dtype='int64')... | Shape: (9000, 40)\n",
      "Accuracy: 59.69%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ATTACK     0.9968    0.2057    0.3411      4564\n",
      "      BENIGN     0.5501    0.9993    0.7096      4436\n",
      "\n",
      "    accuracy                         0.5969      9000\n",
      "   macro avg     0.7735    0.6025    0.5254      9000\n",
      "weighted avg     0.7767    0.5969    0.5227      9000\n",
      "\n",
      "Confusion Matrix: Positive == BENIGN\n",
      "TN: 939, FP: 3625, FN: 3, TP: 4433\n",
      "Predictions on Adversarial Attacks | Indices: Index([58311, 7703, 25104, 22457, 103581], dtype='int64')... | Shape: (9000, 2)\n",
      "Running attack using 24 CPU cores...\n",
      "\n",
      "Process 148716 is generating adversarial examples for batch of size 375 \n",
      "Process 148715 is generating adversarial examples for batch of size 375 \n",
      "Process 148718 is generating adversarial examples for batch of size 375 \n",
      "Process 148717 is generating adversarial examples for batch of size 375 \n",
      "Process 148719 is generating adversarial examples for batch of size 375 \n",
      "Process 148720 is generating adversarial examples for batch of size 375 \n",
      "Process 148721 is generating adversarial examples for batch of size 375 \n",
      "Process 148722 is generating adversarial examples for batch of size 375 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Process 148724 is generating adversarial examples for batch of size 375 \n",
      "Process 148725 is generating adversarial examples for batch of size 375 \n",
      "Process 148723 is generating adversarial examples for batch of size 375 \n",
      "Process 148726 is generating adversarial examples for batch of size 375 \n",
      "Process 148727 is generating adversarial examples for batch of size 375 \n",
      "Process 148728 is generating adversarial examples for batch of size 375 \n",
      "\n",
      "\n",
      "Process 148729 is generating adversarial examples for batch of size 375 \n",
      "\n",
      "Process 148730 is generating adversarial examples for batch of size 375 \n",
      "\n",
      "\n",
      "Process 148732 is generating adversarial examples for batch of size 375 \n",
      "Process 148731 is generating adversarial examples for batch of size 375 \n",
      "\n",
      "Process 148733 is generating adversarial examples for batch of size 375 \n",
      "Process 148734 is generating adversarial examples for batch of size 375 \n",
      "\n",
      "\n",
      "Process 148735 is generating adversarial examples for batch of size 375 \n",
      "\n",
      "\n",
      "Process 148736 is generating adversarial examples for batch of size 375 \n",
      "\n",
      "Process 148737 is generating adversarial examples for batch of size 375 \n",
      "\n",
      "Process 148738 is generating adversarial examples for batch of size 375 \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aaa4e3b71b041969b33c1cf9532c00f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c023c2494ad4814a1bd4c91f354489e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8372595c85c4344a35e28378c7f16a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38eeddffef7d4679a4d7bb68fd6ccb86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f0e667a302943bab711aac2871c4279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e36f2950a52f42f1bed5b95de276c23b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f53fe6b62db42f6aca417520e5691e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f951c5b57ca44bc9154007c6a7870de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21847b38f06c41bdb45f79be38c6f306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05a0a44380df4fac82c64bb393de34d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddd1e69e3033477985f263355999cca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71d0197bd32b4d49bb271d84f0b2d641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cae2fdb3ca747e3821e96f665b5deeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dc66d5748064956a8365685ba76a51a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b17e831a01846aeaaa5d9120499cf58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "968904633b094fe68a1d82e8a41477a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "741eaba1c15e46a388b63d4be2ebd469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a7d246ced8b47b7836131697fd8c84e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "145d1658261e4a8ba2d3c2cb3f12e7ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4532769cb169424ba91f4cf25e7d9845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "947bc3912454440d93f88cd90f4c3855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22446e4c4f194a81b1593eae21251a1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ec69e0afa634a12a36a38836dfce5d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6caba683c0e342ce9a6290d31c8ce468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create CW Adversarial Attack | Indices: Index([67481, 114205, 61838, 66711, 85497], dtype='int64')... | Shape: (9000, 40)\n",
      "Accuracy: 90.73%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ATTACK     1.0000    0.8155    0.8984      4521\n",
      "      BENIGN     0.8430    1.0000    0.9148      4479\n",
      "\n",
      "    accuracy                         0.9073      9000\n",
      "   macro avg     0.9215    0.9078    0.9066      9000\n",
      "weighted avg     0.9219    0.9073    0.9066      9000\n",
      "\n",
      "Confusion Matrix: Positive == BENIGN\n",
      "TN: 3687, FP: 834, FN: 0, TP: 4479\n",
      "Predictions on Adversarial Attacks | Indices: Index([67481, 114205, 61838, 66711, 85497], dtype='int64')... | Shape: (9000, 2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6a1231d2e0345f38eb6b473574e3f81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "JSMA:   0%|          | 0/9000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial JSMA examples generated. Shape: (9000, 40)\n",
      "Create JSMA Adversarial Attack | Indices: Index([25100, 25692, 9516, 17747, 121254], dtype='int64')... | Shape: (9000, 40)\n",
      "Accuracy: 49.84%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ATTACK     0.0000    0.0000    0.0000      4514\n",
      "      BENIGN     0.4984    1.0000    0.6653      4486\n",
      "\n",
      "    accuracy                         0.4984      9000\n",
      "   macro avg     0.2492    0.5000    0.3326      9000\n",
      "weighted avg     0.2484    0.4984    0.3316      9000\n",
      "\n",
      "Confusion Matrix: Positive == BENIGN\n",
      "TN: 0, FP: 4514, FN: 0, TP: 4486\n",
      "Predictions on Adversarial Attacks | Indices: Index([25100, 25692, 9516, 17747, 121254], dtype='int64')... | Shape: (9000, 2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c647149a9fdd48dab6129ac39756eea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial PGD examples generated. Shape: (9000, 40)\n",
      "Create HSJ Adversarial Attack | Indices: Index([30869, 123704, 60521, 54227, 35893], dtype='int64')... | Shape: (9000, 40)\n",
      "Accuracy: 56.59%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ATTACK     1.0000    0.1189    0.2125      4434\n",
      "      BENIGN     0.5389    1.0000    0.7004      4566\n",
      "\n",
      "    accuracy                         0.5659      9000\n",
      "   macro avg     0.7694    0.5594    0.4564      9000\n",
      "weighted avg     0.7661    0.5659    0.4600      9000\n",
      "\n",
      "Confusion Matrix: Positive == BENIGN\n",
      "TN: 527, FP: 3907, FN: 0, TP: 4566\n",
      "Predictions on Adversarial Attacks | Indices: Index([30869, 123704, 60521, 54227, 35893], dtype='int64')... | Shape: (9000, 2)\n"
     ]
    }
   ],
   "source": [
    "import functions.attack_generator as ag\n",
    "import importlib\n",
    "import numpy as np\n",
    "importlib.reload(ag)\n",
    "\n",
    "all_features = dataset.drop(columns=[' Label'])\n",
    "art_model = ag.convert_to_art_model(ids_model, X_train) # TODO: use all features for generating art model\n",
    "\n",
    "# Split the training data into classes\n",
    "class_labels = [\"normal\", \"cw\", \"fgsm\", \"jsma\", \"pgd\"]\n",
    "splits = ag.split_into_attack_classes(X_train, y_train, class_labels)\n",
    "X_normal, y_normal = splits[\"normal\"]\n",
    "X_cw, y_cw = splits[\"cw\"]\n",
    "X_fgsm, y_fgsm = splits[\"fgsm\"]\n",
    "X_jsma, y_jsma = splits[\"jsma\"]\n",
    "X_pgd, y_pgd = splits[\"pgd\"]\n",
    "print(f\"Normal Data: {X_normal.shape} | CW Data: {X_cw.shape} | FGSM Data: {X_fgsm.shape} | JSMA Data: {X_jsma.shape} | PGD Data: {X_pgd.shape}\")\n",
    "\n",
    "# generate attacks on the separated training data\n",
    "# TODO: when changing epsilon, the detector accuracy rises\n",
    "X_adv_fgsm = ag.generate_fgsm_attacks(art_model, X_fgsm, target_label=1)\n",
    "print(f\"Create FGSM Adversarial Attack | Indices: {X_adv_fgsm.index[:5]}... | Shape: {X_adv_fgsm.shape}\")\n",
    "y_pred_adv_fgsm = ag.evaluate_art_model(art_model, X_adv_fgsm, y_fgsm)\n",
    "print(f\"Predictions on Adversarial Attacks | Indices: {y_pred_adv_fgsm.index[:5]}... | Shape: {y_pred_adv_fgsm.shape}\")\n",
    "y_pred_fgsm = y_pred.loc[X_fgsm.index]\n",
    "\n",
    "import multiprocessing\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "X_adv_cw = ag.generate_cw_attacks_parallel(art_model, X_cw, target_label=1, num_cores=num_cores)\n",
    "print(f\"Create CW Adversarial Attack | Indices: {X_adv_cw.index[:5]}... | Shape: {X_adv_cw.shape}\")\n",
    "y_pred_adv_cw = ag.evaluate_art_model(art_model, X_adv_cw, y_cw)\n",
    "print(f\"Predictions on Adversarial Attacks | Indices: {y_pred_adv_cw.index[:5]}... | Shape: {y_pred_adv_cw.shape}\")\n",
    "y_pred_cw = y_pred.loc[X_cw.index]\n",
    "\n",
    "X_adv_jsma = ag.generate_jsma_attacks(art_model, X_jsma, target_label=1)\n",
    "print(f\"Create JSMA Adversarial Attack | Indices: {X_adv_jsma.index[:5]}... | Shape: {X_adv_jsma.shape}\")\n",
    "y_pred_adv_jsma = ag.evaluate_art_model(art_model, X_adv_jsma, y_jsma)\n",
    "print(f\"Predictions on Adversarial Attacks | Indices: {y_pred_adv_jsma.index[:5]}... | Shape: {y_pred_adv_jsma.shape}\")\n",
    "y_pred_jsma = y_pred.loc[X_jsma.index]\n",
    "\n",
    "X_adv_pgd = ag.generate_pgd_attacks(art_model, X_pgd, target_label=1)\n",
    "print(f\"Create HSJ Adversarial Attack | Indices: {X_adv_pgd.index[:5]}... | Shape: {X_adv_pgd.shape}\")\n",
    "y_pred_adv_pgd = ag.evaluate_art_model(art_model, X_adv_pgd, y_pgd)\n",
    "print(f\"Predictions on Adversarial Attacks | Indices: {y_pred_adv_pgd.index[:5]}... | Shape: {y_pred_adv_pgd.shape}\")\n",
    "y_pred_pgd = y_pred.loc[X_pgd.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correctly_benign_classified_indices(y_train, y_pred):\n",
    "    benign_indices = y_train[y_train['BENIGN'] == 1].index\n",
    "    benign_adv_predicted_indices = y_pred[y_pred['BENIGN'] == 1].index\n",
    "    correctly_benign_classified_indices = benign_indices.intersection(benign_adv_predicted_indices)\n",
    "    return correctly_benign_classified_indices\n",
    "\n",
    "def get_misclassified_as_benign_due_attack_indices(y_train, y_pred, y_pred_adv):\n",
    "    attack_indices = y_train[y_train['ATTACK'] == 1].index\n",
    "    attack_adv_predicted_indices = y_pred[y_pred['ATTACK'] == 1].index\n",
    "    benign_predicted_adversarial_indices = y_pred_adv[y_pred_adv['BENIGN'] == 1].index\n",
    "    misclassified_as_benign_due_attack_indices = attack_indices.intersection(attack_adv_predicted_indices).intersection(benign_predicted_adversarial_indices)\n",
    "    return misclassified_as_benign_due_attack_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly classified as BENIGN from the IDS: 4426 | Indices: Index([36792, 80908, 47406], dtype='int64')\n",
      "    Correctly classified as BENIGN from the IDS (FGSM): 4433 | Indices: Index([7703, 22457, 63618], dtype='int64')\n",
      "    ATTACK sample misclassified as BENIGN due to adversarial attack (FGSM): 3577 | Indices: Index([58311, 25104, 103581], dtype='int64')\n",
      "        Correctly classified as BENIGN from the IDS (CW): 4414 | Indices: Index([114205, 61838, 66711], dtype='int64')\n",
      "        ATTACK sample misclassified as BENIGN due to adversarial attack (CW): 762 | Indices: Index([67481, 85497, 74557], dtype='int64')\n",
      "            Correctly classified as BENIGN from the IDS (PGD): 4498 | Indices: Index([30869, 123704, 113616], dtype='int64')\n",
      "            ATTACK sample misclassified as BENIGN due to adversarial attack (PGD): 3852 | Indices: Index([54227, 35893, 13435], dtype='int64')\n",
      "                Correctly classified as BENIGN from the IDS (JSMA): 4423 | Indices: Index([25100, 113779, 90291], dtype='int64')\n",
      "                ATTACK sample misclassified as BENIGN due to adversarial attack (JSMA): 4452 | Indices: Index([25692, 9516, 17747], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "y_pred_normal = y_pred.loc[X_normal.index]\n",
    "correctly_benign_classified_indices = get_correctly_benign_classified_indices(y_normal, y_pred_normal)\n",
    "\n",
    "correctly_benign_classified_indices_fgsm = get_correctly_benign_classified_indices(y_fgsm, y_pred_adv_fgsm)\n",
    "misclassified_as_benign_due_attack_indices_fgsm = get_misclassified_as_benign_due_attack_indices(y_fgsm, y_pred_fgsm, y_pred_adv_fgsm)\n",
    "\n",
    "correctly_benign_classified_indices_cw = get_correctly_benign_classified_indices(y_cw, y_pred_cw)\n",
    "misclassified_as_benign_due_attack_indices_cw = get_misclassified_as_benign_due_attack_indices(y_cw, y_pred_cw, y_pred_adv_cw)\n",
    "\n",
    "correctly_benign_classified_indices_jsma = get_correctly_benign_classified_indices(y_jsma, y_pred_jsma)\n",
    "misclassified_as_benign_due_attack_indices_jsma = get_misclassified_as_benign_due_attack_indices(y_jsma, y_pred_jsma, y_pred_adv_jsma)\n",
    "\n",
    "# TODO: is it correct to only include the samples that are correctly classified from the IDS?\n",
    "correctly_benign_classified_indices_pgd = get_correctly_benign_classified_indices(y_pgd, y_pred_pgd)\n",
    "misclassified_as_benign_due_attack_indices_pgd = get_misclassified_as_benign_due_attack_indices(y_pgd, y_pred_pgd, y_pred_adv_pgd)\n",
    "\n",
    "print(f\"Correctly classified as BENIGN from the IDS: {len(correctly_benign_classified_indices)} | Indices: {correctly_benign_classified_indices[:3]}\")\n",
    "print(f\"    Correctly classified as BENIGN from the IDS (FGSM): {len(correctly_benign_classified_indices_fgsm)} | Indices: {correctly_benign_classified_indices_fgsm[:3]}\")\n",
    "print(f\"    ATTACK sample misclassified as BENIGN due to adversarial attack (FGSM): {len(misclassified_as_benign_due_attack_indices_fgsm)} | Indices: {misclassified_as_benign_due_attack_indices_fgsm[:3]}\")\n",
    "print(f\"        Correctly classified as BENIGN from the IDS (CW): {len(correctly_benign_classified_indices_cw)} | Indices: {correctly_benign_classified_indices_cw[:3]}\")\n",
    "print(f\"        ATTACK sample misclassified as BENIGN due to adversarial attack (CW): {len(misclassified_as_benign_due_attack_indices_cw)} | Indices: {misclassified_as_benign_due_attack_indices_cw[:3]}\")\n",
    "print(f\"            Correctly classified as BENIGN from the IDS (PGD): {len(correctly_benign_classified_indices_pgd)} | Indices: {correctly_benign_classified_indices_pgd[:3]}\")\n",
    "print(f\"            ATTACK sample misclassified as BENIGN due to adversarial attack (PGD): {len(misclassified_as_benign_due_attack_indices_pgd)} | Indices: {misclassified_as_benign_due_attack_indices_pgd[:3]}\")\n",
    "print(f\"                Correctly classified as BENIGN from the IDS (JSMA): {len(correctly_benign_classified_indices_jsma)} | Indices: {correctly_benign_classified_indices_jsma[:3]}\")\n",
    "print(f\"                ATTACK sample misclassified as BENIGN due to adversarial attack (JSMA): {len(misclassified_as_benign_due_attack_indices_jsma)} | Indices: {misclassified_as_benign_due_attack_indices_jsma[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions.visualizer as visualizer\n",
    "# import importlib\n",
    "# importlib.reload(visualizer)\n",
    "\n",
    "# visualizer.visualize_data_distribution(X_train.loc[correctly_benign_classified_indices], 'Normal Data', X_adv_fgsm.loc[misclassified_as_benign_due_attack_indices_fgsm], 'Adversarial Data')\n",
    "# # visualizer.visualize_data_distribution(X_train.loc[misclassified_as_benign_due_attack_indices], 'Normal Data', X_adv.loc[misclassified_as_benign_due_attack_indices], 'Adversarial Data', side_by_side=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PermutationExplainer explainer: 9001it [03:58, 36.14it/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate Explanations | Indices: Index([36792, 41605, 80908, 47406, 128924], dtype='int64')... | Shape: (9000, 40)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PermutationExplainer explainer: 9001it [04:13, 34.06it/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate FGSM Adversarial Explanations | Indices: Index([58311, 7703, 25104, 22457, 103581], dtype='int64')... | Shape: (9000, 40)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PermutationExplainer explainer: 9001it [04:03, 35.40it/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate CW Adversarial Explanations | Indices: Index([67481, 114205, 61838, 66711, 85497], dtype='int64')... | Shape: (9000, 40)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PermutationExplainer explainer: 9001it [04:04, 35.23it/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate JSMA Adversarial Explanations | Indices: Index([25100, 25692, 9516, 17747, 121254], dtype='int64')... | Shape: (9000, 40)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PermutationExplainer explainer: 9001it [04:10, 34.54it/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate PGD Adversarial Explanations | Indices: Index([30869, 123704, 60521, 54227, 35893], dtype='int64')... | Shape: (9000, 40)\n"
     ]
    }
   ],
   "source": [
    "import functions.explainer as exp\n",
    "import importlib\n",
    "importlib.reload(exp)\n",
    "\n",
    "explainer = exp.generate_shap_explainer(ids_model, X_train)\n",
    "\n",
    "shap_values_df = exp.generate_shap_values(explainer, X_normal)\n",
    "print(f\"Generate Explanations | Indices: {shap_values_df.index[:5]}... | Shape: {shap_values_df.shape}\")\n",
    "\n",
    "shap_values_adv_df_fgsm = exp.generate_shap_values(explainer, X_adv_fgsm)\n",
    "print(f\"Generate FGSM Adversarial Explanations | Indices: {shap_values_adv_df_fgsm.index[:5]}... | Shape: {shap_values_adv_df_fgsm.shape}\")\n",
    "\n",
    "shap_values_adv_df_cw = exp.generate_shap_values(explainer, X_adv_cw)\n",
    "print(f\"Generate CW Adversarial Explanations | Indices: {shap_values_adv_df_cw.index[:5]}... | Shape: {shap_values_adv_df_cw.shape}\")\n",
    "\n",
    "shap_values_adv_df_jsma = exp.generate_shap_values(explainer, X_adv_jsma)\n",
    "print(f\"Generate JSMA Adversarial Explanations | Indices: {shap_values_adv_df_jsma.index[:5]}... | Shape: {shap_values_adv_df_jsma.shape}\")\n",
    "\n",
    "shap_values_adv_df_pgd = exp.generate_shap_values(explainer, X_adv_pgd)\n",
    "print(f\"Generate PGD Adversarial Explanations | Indices: {shap_values_adv_df_pgd.index[:5]}... | Shape: {shap_values_adv_df_pgd.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions.visualizer as visualizer\n",
    "# import importlib\n",
    "# importlib.reload(visualizer)\n",
    "\n",
    "# visualizer.visualize_data_distribution(shap_values_df.loc[correctly_benign_classified_indices], 'Normal Explanations', shap_values_adv_df_fgsm.loc[misclassified_as_benign_due_attack_indices_fgsm], 'Adversarial Explanations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp.plot_shap_summary_comparison(shap_values_df.loc[correctly_benign_classified_indices].values, X_train.loc[correctly_benign_classified_indices], shap_values_adv_df.loc[misclassified_as_benign_due_attack_indices].values, X_adv.loc[misclassified_as_benign_due_attack_indices], 6, title='Normal vs Adversarial Explanations of Benign Samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "adv_concat_correctly_benign_classified_shaps = pd.concat([\n",
    "    shap_values_adv_df_fgsm.loc[correctly_benign_classified_indices_fgsm],\n",
    "    shap_values_adv_df_pgd.loc[correctly_benign_classified_indices_pgd],\n",
    "    ], axis=0)\n",
    "# shap_values_df.loc[misclassified_as_benign_due_attack_indices]\n",
    "adv_concat_misclassified_as_benign_shaps = pd.concat([\n",
    "    shap_values_adv_df_fgsm.loc[misclassified_as_benign_due_attack_indices_fgsm], \n",
    "    shap_values_adv_df_pgd.loc[misclassified_as_benign_due_attack_indices_pgd],\n",
    "    # shap_values_adv_df_cw.loc[misclassified_as_benign_due_attack_indices_cw],\n",
    "    # shap_values_adv_df_jsma.loc[misclassified_as_benign_due_attack_indices_jsma],\n",
    "    ], axis=0)\n",
    "\n",
    "concat_correct_benign_shaps = pd.concat([\n",
    "    shap_values_df.loc[correctly_benign_classified_indices], \n",
    "    shap_values_adv_df_cw.loc[correctly_benign_classified_indices_cw],\n",
    "    shap_values_adv_df_jsma.loc[correctly_benign_classified_indices_jsma],\n",
    "    ], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 'ADV CORRECT BENIGN' | Shape: (8931, 40)\n",
      " 'ADV MISCLASSIFIED' | Shape: (7429, 40)\n",
      " 'CW MISCLASSIFIED' | Shape: (762, 40)\n",
      " 'JSMA MISCLASSIFIED' | Shape: (4452, 40)\n",
      " 'CORRECT BENIGN' | Shape: (13263, 40)\n"
     ]
    }
   ],
   "source": [
    "class_samples = {\n",
    "    'ADV CORRECT BENIGN': adv_concat_correctly_benign_classified_shaps,\n",
    "    'ADV MISCLASSIFIED': adv_concat_misclassified_as_benign_shaps,\n",
    "    'CW MISCLASSIFIED': shap_values_adv_df_cw.loc[misclassified_as_benign_due_attack_indices_cw],\n",
    "    'JSMA MISCLASSIFIED': shap_values_adv_df_jsma.loc[misclassified_as_benign_due_attack_indices_jsma],\n",
    "    'CORRECT BENIGN': concat_correct_benign_shaps, \n",
    "}\n",
    "\n",
    "print(f\" 'ADV CORRECT BENIGN' | Shape: {adv_concat_correctly_benign_classified_shaps.shape}\")\n",
    "print(f\" 'ADV MISCLASSIFIED' | Shape: {adv_concat_misclassified_as_benign_shaps.shape}\")\n",
    "print(f\" 'CW MISCLASSIFIED' | Shape: {shap_values_adv_df_cw.loc[misclassified_as_benign_due_attack_indices_cw].shape}\")\n",
    "print(f\" 'JSMA MISCLASSIFIED' | Shape: {shap_values_adv_df_jsma.loc[misclassified_as_benign_due_attack_indices_jsma].shape}\")\n",
    "print(f\" 'CORRECT BENIGN' | Shape: {concat_correct_benign_shaps.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.manifold import TSNE\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# # Optional: UMAP (must be installed separately)\n",
    "# try:\n",
    "#     import umap\n",
    "#     UMAP_AVAILABLE = True\n",
    "# except ImportError:\n",
    "#     UMAP_AVAILABLE = False\n",
    "\n",
    "# def plot_dim_reduction(X, y_onehot, class_labels, method=\"pca\", **kwargs):\n",
    "#     \"\"\"\n",
    "#     Plots dimensionality-reduced data using PCA, t-SNE, or UMAP.\n",
    "\n",
    "#     Args:\n",
    "#         X (ndarray or DataFrame): Feature matrix.\n",
    "#         y_onehot (ndarray): One-hot encoded labels.\n",
    "#         class_labels (list of str): Class label names.\n",
    "#         method (str): 'pca', 'tsne', or 'umap'.\n",
    "#         **kwargs: Additional arguments for the reducer (e.g., perplexity for t-SNE).\n",
    "#     \"\"\"\n",
    "#     y_indices = np.argmax(y_onehot, axis=1)\n",
    "\n",
    "#     if method == \"pca\":\n",
    "#         reducer = PCA(n_components=2)\n",
    "#     elif method == \"tsne\":\n",
    "#         reducer = TSNE(n_components=2, random_state=42, **kwargs)\n",
    "#     elif method == \"umap\":\n",
    "#         if not UMAP_AVAILABLE:\n",
    "#             raise ImportError(\"UMAP is not installed. Run: pip install umap-learn\")\n",
    "#         reducer = umap.UMAP(n_components=2, random_state=42, **kwargs)\n",
    "#     else:\n",
    "#         raise ValueError(\"Invalid method. Choose from 'pca', 'tsne', or 'umap'.\")\n",
    "\n",
    "#     X_reduced = reducer.fit_transform(X)\n",
    "\n",
    "#     # Plot\n",
    "#     plt.figure(figsize=(10, 8))\n",
    "#     for i, label in enumerate(class_labels):\n",
    "#         idx = y_indices == i\n",
    "#         plt.scatter(X_reduced[idx, 0], X_reduced[idx, 1], label=label, alpha=0.6)\n",
    "\n",
    "#     plt.title(f\"{method.upper()} Projection of SHAP Values\")\n",
    "#     plt.xlabel(\"Component 1\")\n",
    "#     plt.ylabel(\"Component 2\")\n",
    "#     plt.legend()\n",
    "#     plt.grid(True)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# # Choose method: 'pca', 'tsne', or 'umap'\n",
    "# # plot_dim_reduction(X, y, class_labels, method=\"tsne\", perplexity=30)\n",
    "# plot_dim_reduction(X, y, class_labels, method=\"pca\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated dataset: X shape (34837, 40), y shape (34837, 5)\n",
      "(34837, 40) (34837, 5)\n",
      "(31353, 40) (3484, 40) (31353, 5) (3484, 5)\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 16:12:21.664856: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6147 - loss: 1.0186 - val_accuracy: 0.9351 - val_loss: 0.2227\n",
      "Epoch 2/20\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 988us/step - accuracy: 0.9041 - loss: 0.3064 - val_accuracy: 0.9520 - val_loss: 0.1501\n",
      "Epoch 3/20\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9274 - loss: 0.2326 - val_accuracy: 0.9542 - val_loss: 0.1364\n",
      "Epoch 4/20\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9348 - loss: 0.2099 - val_accuracy: 0.9584 - val_loss: 0.1269\n",
      "Epoch 5/20\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9383 - loss: 0.1960 - val_accuracy: 0.9598 - val_loss: 0.1221\n",
      "Epoch 6/20\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9406 - loss: 0.1804 - val_accuracy: 0.9606 - val_loss: 0.1184\n",
      "Epoch 7/20\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9474 - loss: 0.1668 - val_accuracy: 0.9606 - val_loss: 0.1132\n",
      "Epoch 8/20\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9470 - loss: 0.1610 - val_accuracy: 0.9619 - val_loss: 0.1109\n",
      "Epoch 9/20\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9478 - loss: 0.1569 - val_accuracy: 0.9620 - val_loss: 0.1085\n",
      "Epoch 10/20\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9485 - loss: 0.1525 - val_accuracy: 0.9646 - val_loss: 0.1040\n",
      "Epoch 11/20\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9493 - loss: 0.1513 - val_accuracy: 0.9657 - val_loss: 0.1010\n",
      "Epoch 12/20\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9523 - loss: 0.1421 - val_accuracy: 0.9654 - val_loss: 0.0995\n",
      "Epoch 13/20\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9532 - loss: 0.1386 - val_accuracy: 0.9656 - val_loss: 0.0973\n",
      "Epoch 14/20\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9535 - loss: 0.1342 - val_accuracy: 0.9665 - val_loss: 0.0966\n",
      "Epoch 15/20\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9547 - loss: 0.1323 - val_accuracy: 0.9652 - val_loss: 0.0945\n",
      "Epoch 16/20\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9547 - loss: 0.1257 - val_accuracy: 0.9664 - val_loss: 0.0962\n",
      "Epoch 17/20\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9531 - loss: 0.1285 - val_accuracy: 0.9675 - val_loss: 0.0926\n",
      "Epoch 18/20\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9553 - loss: 0.1240 - val_accuracy: 0.9678 - val_loss: 0.0919\n",
      "Epoch 19/20\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9562 - loss: 0.1261 - val_accuracy: 0.9675 - val_loss: 0.0909\n",
      "Epoch 20/20\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9588 - loss: 0.1220 - val_accuracy: 0.9683 - val_loss: 0.0895\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 16:12:36.810338: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    }
   ],
   "source": [
    "import functions.detector as det\n",
    "import importlib\n",
    "importlib.reload(det)\n",
    "\n",
    "# create dataframe\n",
    "class_samples = {\n",
    "    'ADV CORRECT BENIGN': adv_concat_correctly_benign_classified_shaps,\n",
    "    'ADV MISCLASSIFIED': adv_concat_misclassified_as_benign_shaps,\n",
    "    'CW MISCLASSIFIED': shap_values_adv_df_cw.loc[misclassified_as_benign_due_attack_indices_cw],\n",
    "    'JSMA MISCLASSIFIED': shap_values_adv_df_jsma.loc[misclassified_as_benign_due_attack_indices_jsma],\n",
    "    'CORRECT BENIGN': concat_correct_benign_shaps, \n",
    "}\n",
    "X, y = det.build_detector_dataset(class_samples)\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "# split data\n",
    "X_train_det, X_test_det, y_train_det, y_test_det = train_test_split(X, y, test_size=0.1, random_state=1503)\n",
    "print(X_train_det.shape, X_test_det.shape, y_train_det.shape, y_test_det.shape)\n",
    "\n",
    "# build detector\n",
    "detector = det.build_detector(X_train_det, y_train_det, X_test_det, y_test_det)\n",
    "\n",
    "# store detector\n",
    "det.store(detector, 'ny')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m104/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 486us/step"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step\n",
      "Predictions on Detector | Indices: Index([24807, 24366, 7586, 134723, 22511], dtype='int64')... | Shape: (3484, 5)\n",
      "[1 4 1 3 4] [1 4 1 3 4]\n",
      "Overall Accuracy: 0.9656\n",
      "Classification Report (Overall):\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "ADV CORRECT BENIGN       0.92      0.98      0.95       947\n",
      " ADV MISCLASSIFIED       0.97      0.89      0.93       724\n",
      "  CW MISCLASSIFIED       0.81      0.91      0.86        69\n",
      "JSMA MISCLASSIFIED       0.99      0.99      0.99       420\n",
      "    CORRECT BENIGN       1.00      0.99      0.99      1324\n",
      "\n",
      "          accuracy                           0.97      3484\n",
      "         macro avg       0.94      0.95      0.94      3484\n",
      "      weighted avg       0.97      0.97      0.97      3484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate detector\n",
    "y_pred_det = det.predict(detector, X_test_det, y.columns)\n",
    "print(f\"Predictions on Detector | Indices: {y_pred_det.index[:5]}... | Shape: {y_pred_det.shape}\")\n",
    "\n",
    "# Convert one-hot to class indices\n",
    "y_true_indices = np.argmax(y_test_det, axis=1)\n",
    "y_true_indices_pd = pd.Series(y_true_indices, index=y_test_det.index)\n",
    "y_pred_indices = np.argmax(y_pred_det, axis=1)\n",
    "y_pred_indices_pd = pd.Series(y_pred_indices, index=y_pred_det.index)\n",
    "print(y_true_indices[:5], y_pred_indices[:5])\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Compute Accuracy\n",
    "accuracy = accuracy_score(y_true_indices, y_pred_indices)\n",
    "print(f\"Overall Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Compute Classification Report for overall classification\n",
    "print(\"Classification Report (Overall):\")\n",
    "print(classification_report(y_true_indices, y_pred_indices, target_names=y.columns, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Manual Evaluation\n",
    "We perform the whole two-stages approach on new unseen data and evaluate the following scores:\n",
    "- Recall\n",
    "- Precision\n",
    "- Accuracy\n",
    "- F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Preprocessing data --\n",
      "--- Splitting labels and features ---\n",
      "--- Encoding labels as binary one-hot values ---\n",
      "--- Sampling balanced data ---\n",
      "Sample to shape: (1000, 40)\n",
      "--- Normalizing features using MinMaxScaler ---\n",
      "Generate Features | Indices: Index([68520, 129860, 118208, 50067, 32481], dtype='int64')... | Shape: (1000, 40)\n",
      "Generate Labels | Indices: Index([68520, 129860, 118208, 50067, 32481], dtype='int64')... | Shape: (1000, 2)\n",
      "BENIGN  ATTACK\n",
      "False   True      500\n",
      "True    False     500\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import functions.data_preprocessing as dp\n",
    "import importlib\n",
    "importlib.reload(dp)\n",
    "\n",
    "# exclude previously used samples\n",
    "dataset_eval_excluded = dataset.drop(index=used_indices)\n",
    "\n",
    "X_eval, y_eval, used_eval_indices = dp.preprocess_data(dataset_eval_excluded, encoding_type, normalizer, zero_columns, sample_size=500, random_sample_state=17)\n",
    "print(f\"Generate Features | Indices: {X_eval.index[:5]}... | Shape: {X_eval.shape}\")\n",
    "print(f\"Generate Labels | Indices: {y_eval.index[:5]}... | Shape: {y_eval.shape}\")\n",
    "print(y_eval.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions.detector as det\n",
    "# importlib.reload(det)\n",
    "# detector = det.load('ny')\n",
    "\n",
    "# explainer = exp.generate_shap_explainer(ids_model, X_train)\n",
    "\n",
    "# all_features = dataset.drop(columns=[' Label'])\n",
    "# art_model = ag.convert_to_art_model(ids_model, X_train) # TODO: use all features for generating art model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running attack using 24 CPU cores...\n",
      "\n",
      "Process 204772 is generating adversarial examples for batch of size 41 \n",
      "Process 204775 is generating adversarial examples for batch of size 41 \n",
      "Process 204770 is generating adversarial examples for batch of size 41 \n",
      "Process 204774 is generating adversarial examples for batch of size 41 \n",
      "Process 204771 is generating adversarial examples for batch of size 41 \n",
      "Process 204773 is generating adversarial examples for batch of size 41 \n",
      "Process 204776 is generating adversarial examples for batch of size 41 \n",
      "Process 204778 is generating adversarial examples for batch of size 41 \n",
      "Process 204777 is generating adversarial examples for batch of size 41 \n",
      "Process 204779 is generating adversarial examples for batch of size 41 \n",
      "Process 204781 is generating adversarial examples for batch of size 41 \n",
      "Process 204780 is generating adversarial examples for batch of size 41 \n",
      "Process 204783 is generating adversarial examples for batch of size 41 \n",
      "Process 204785 is generating adversarial examples for batch of size 41 \n",
      "Process 204786 is generating adversarial examples for batch of size 41 \n",
      "Process 204787 is generating adversarial examples for batch of size 41 \n",
      "Process 204784 is generating adversarial examples for batch of size 41 \n",
      "Process 204782 is generating adversarial examples for batch of size 41 \n",
      "Process 204788 is generating adversarial examples for batch of size 41 \n",
      "Process 204789 is generating adversarial examples for batch of size 41 \n",
      "Process 204790 is generating adversarial examples for batch of size 41 \n",
      "Process 204791 is generating adversarial examples for batch of size 41 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Process 204792 is generating adversarial examples for batch of size 41 \n",
      "Process 204793 is generating adversarial examples for batch of size 57 \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "297d8a91bdbc45cd85d57ba07759c569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f95b828848c4c6081f98ca10228809b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7924367014584b818795803214f73678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a19a9ccaa43b4d9c9b38b7e9538bbc21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4cdec4702d44b29b301fca53e22491d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe789479298d4bd2bd2310ea13ffa51b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb488dd0b5c4713a1f6d6483819af26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccc1a28c6d7549cda4ef9f0796c2e0ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3618400d745a4cc69fc18d1de127b06d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7551a51ca5a244acb6d478332cfe8d2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a76ed082ac92433ba7464a5eaf57e9b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85089a0b0531443ea065023444f1cf38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b286e6c8057941759be3935044049532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5a5184799bd42d6b803273fa909ad24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a867c4c5bdc416d8ae8ea7163d2f264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c90f54f78854d6aaa0b5bc557792b71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc4f7bdb1484ec6b4b7f6e1243af655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eff428c5da2d42f6ab2425dff378f8a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a6baa0aa19342d18962bccc0d8400cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ee32985286d4365b445ae9e575e89e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b168f02e9ec40b29f36744ed1cd4a84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c989448058463fbb32b2aae3c0903e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85f0574891364aceb590e0bc506a7656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab161f7794154a0c8021eb465cc62ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Adversarial Attack | Indices: Index([68520, 129860, 118208, 50067, 32481], dtype='int64')... | Shape: (1000, 40)\n",
      "Accuracy: 90.80%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ATTACK     0.9976    0.8180    0.8989       500\n",
      "      BENIGN     0.8458    0.9980    0.9156       500\n",
      "\n",
      "    accuracy                         0.9080      1000\n",
      "   macro avg     0.9217    0.9080    0.9072      1000\n",
      "weighted avg     0.9217    0.9080    0.9072      1000\n",
      "\n",
      "Confusion Matrix: Positive == BENIGN\n",
      "TN: 409, FP: 91, FN: 1, TP: 499\n",
      "Predictions on Adversarial Attacks | Indices: Index([68520, 129860, 118208, 50067, 32481], dtype='int64')... | Shape: (1000, 2)\n"
     ]
    }
   ],
   "source": [
    "import functions.attack_generator as ag\n",
    "importlib.reload(ag)\n",
    "\n",
    "X_adv_eval = ag.generate_cw_attacks_parallel(art_model, X_eval, target_label=1, num_cores=num_cores)\n",
    "print(f\"Create Adversarial Attack | Indices: {X_adv_eval.index[:5]}... | Shape: {X_adv_eval.shape}\")\n",
    "\n",
    "y_pred_adv_eval = ag.evaluate_art_model(art_model, X_adv_eval, y_eval)\n",
    "print(f\"Predictions on Adversarial Attacks | Indices: {y_pred_adv_eval.index[:5]}... | Shape: {y_pred_adv_eval.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PermutationExplainer explainer: 1001it [00:27, 23.58it/s]                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Explanations | Indices: Index([68520, 129860, 118208, 50067, 32481], dtype='int64')... | Shape: (1000, 40)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import functions.explainer as exp\n",
    "importlib.reload(exp)\n",
    "X_eval_adv_shap_values_df = exp.generate_shap_values(explainer, X_adv_eval)\n",
    "\n",
    "print(f\"Create Explanations | Indices: {X_eval_adv_shap_values_df.index[:5]}... | Shape: {X_eval_adv_shap_values_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # normal shap values\n",
    "\n",
    "# y_pred_adv_eval = ag.evaluate_art_model(art_model, X_eval, y_eval)\n",
    "# print(f\"Predictions on Adversarial Attacks | Indices: {y_pred_adv_eval.index[:5]}... | Shape: {y_pred_adv_eval.shape}\")\n",
    "\n",
    "# X_eval_adv_shap_values_df = exp.generate_shap_values(explainer, X_eval)\n",
    "\n",
    "# print(f\"Create Explanations | Indices: {X_eval_adv_shap_values_df.index[:5]}... | Shape: {X_eval_adv_shap_values_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 16:22:20.291858: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    }
   ],
   "source": [
    "benign_eval_idx = y_eval[y_eval['BENIGN'] == 1].index\n",
    "attack_eval_idx = y_eval[y_eval['ATTACK'] == 1].index\n",
    "\n",
    "pred_benign_idx = y_pred_adv_eval[y_pred_adv_eval['BENIGN'] == 1].index\n",
    "pred_attack_idx = y_pred_adv_eval[y_pred_adv_eval['ATTACK'] == 1].index\n",
    "\n",
    "# predict\n",
    "X_eval_detector = X_eval_adv_shap_values_df.loc[pred_benign_idx]\n",
    "\n",
    "# TODO: uncommend want to find attacks\n",
    "# print(f\" All Adversarial Samples classified as BENIGN: {X_eval_detector.shape}\")\n",
    "# misclassified_idx = attack_eval_idx.intersection(pred_benign_idx)\n",
    "# X_eval_detector = X_eval_detector.loc[misclassified_idx]\n",
    "# print(f\" Attack Samples misclassified through Adversarial Attack: {X_eval_detector.shape}\")\n",
    "\n",
    "columns = ['ADV CORRECT BENIGN', 'ADV MISCLASSIFIED', 'CW MISCLASSIFIED', 'JSMA MISCLASSIFIED', 'CORRECT BENIGN']\n",
    "# columns = ['ADV CORRECT BENIGN', 'ADV MISCLASSIFIED', 'CORRECT BENIGN']\n",
    "y_pred_eval_detector = det.predict(detector, X_eval_detector, columns)\n",
    "\n",
    "# correctly_classified_det_idx = y_pred_eval_detector[y_pred_eval_detector['BENIGN'] == 1].index\n",
    "# misclassified_det_idx = y_pred_eval_detector[y_pred_eval_detector['ATTACK'] == 1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class 0: 0\n",
      "Predicted Class 1: 0\n",
      "Predicted Class 2: 81\n",
      "Predicted Class 3: 4\n",
      "Predicted Class 4: 504\n"
     ]
    }
   ],
   "source": [
    "pred_class_0 = y_pred_eval_detector[y_pred_eval_detector['ADV CORRECT BENIGN'] == 1].index \n",
    "pred_class_1 = y_pred_eval_detector[y_pred_eval_detector['ADV MISCLASSIFIED'] == 1].index\n",
    "pred_class_2 = y_pred_eval_detector[y_pred_eval_detector['CW MISCLASSIFIED'] == 1].index\n",
    "pred_class_3 = y_pred_eval_detector[y_pred_eval_detector['JSMA MISCLASSIFIED'] == 1].index\n",
    "pred_class_4 = y_pred_eval_detector[y_pred_eval_detector['CORRECT BENIGN'] == 1].index\n",
    "print(f\"Predicted Class 0: {len(pred_class_0)}\")\n",
    "print(f\"Predicted Class 1: {len(pred_class_1)}\")\n",
    "print(f\"Predicted Class 2: {len(pred_class_2)}\")\n",
    "print(f\"Predicted Class 3: {len(pred_class_3)}\")\n",
    "print(f\"Predicted Class 4: {len(pred_class_4)}\") # TODO: .intersection(benign_eval_idx)\n",
    "# TODO: 1 sample missing for normal BENIGN samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDS classifies 'ATTACK' samples as 'ATTACK': 409\n",
      "IDS mis-classifies 'BENIGN' samples as 'ATTACK': 1\n",
      "Detector classifies 'BENIGN' samples as correct 'BENIGN': 485\n",
      "Detector mis-classifies 'ATTACK' samples as correct 'BENIGN': 19\n",
      "Detector classifies 'ATTACK' samples as misclassified due to 'ATTACK': 68\n",
      "Detector classifies 'BENIGN' samples as misclassified due to 'ATTACK': 13\n",
      "TP: 485\n",
      "FP: 19\n",
      "TN: 477\n",
      "FN: 14\n",
      "Sum: 995\n"
     ]
    }
   ],
   "source": [
    "# After IDS Stage\n",
    "TN = len(attack_eval_idx.intersection(pred_attack_idx)) # IDS classifies 'ATTACK' samples as 'ATTACK'\n",
    "print(f\"IDS classifies 'ATTACK' samples as 'ATTACK': {TN}\")\n",
    "FN = len(benign_eval_idx.intersection(pred_attack_idx)) # IDS classifies 'BENIGN' samples as 'ATTACK'\n",
    "print(f\"IDS mis-classifies 'BENIGN' samples as 'ATTACK': {FN}\")\n",
    "\n",
    "# TODO: define correct and misclassified classes for each attack:\n",
    "correctly_classified_det_idx = y_pred_eval_detector.loc[pred_class_4].index # Detector classifies 'BENIGN' samples as correct 'BENIGN'\n",
    "misclassified_det_idx = y_pred_eval_detector.loc[pred_class_2].index # Detector classifies 'ATTACK' samples as misclassified due to 'ATTACK'\n",
    "\n",
    "# After Detector Stage\n",
    "TP = len(benign_eval_idx.intersection(correctly_classified_det_idx)) # Detector classifies 'BENIGN' samples as correct 'BENIGN'\n",
    "print(f\"Detector classifies 'BENIGN' samples as correct 'BENIGN': {TP}\")\n",
    "FP = len(attack_eval_idx.intersection(correctly_classified_det_idx)) # Detector classifies 'ATTACK' samples as correct 'BENIGN'\n",
    "print(f\"Detector mis-classifies 'ATTACK' samples as correct 'BENIGN': {FP}\")\n",
    "\n",
    "TN_2 = len(attack_eval_idx.intersection(misclassified_det_idx)) # Detector classifies 'ATTACK' samples as misclassified due to 'ATTACK'\n",
    "print(f\"Detector classifies 'ATTACK' samples as misclassified due to 'ATTACK': {TN_2}\")\n",
    "FN_2 = len(benign_eval_idx.intersection(misclassified_det_idx)) # Detector classifies 'BENIGN' samples as misclassified due to 'ATTACK'\n",
    "print(f\"Detector classifies 'BENIGN' samples as misclassified due to 'ATTACK': {FN_2}\")\n",
    "\n",
    "# Sum up TN & FN from both stages\n",
    "TN = TN + TN_2\n",
    "FN = FN + FN_2\n",
    "\n",
    "print(f\"TP: {TP}\")\n",
    "print(f\"FP: {FP}\")\n",
    "print(f\"TN: {TN}\")\n",
    "print(f\"FN: {FN}\")\n",
    "print(f\"Sum: {TP + FP + TN + FN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Accuracy: 96.68%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ATTACK     0.9715    0.9617    0.9666       496\n",
      "      BENIGN     0.9623    0.9719    0.9671       499\n",
      "\n",
      "    accuracy                         0.9668       995\n",
      "   macro avg     0.9669    0.9668    0.9668       995\n",
      "weighted avg     0.9669    0.9668    0.9668       995\n",
      "\n",
      "True Negative Rate: 96.17%\n",
      "False Positive Rate: 3.83%\n",
      "True Positive Rate: 97.19%\n",
      "False Negative Rate: 2.81%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(f\"Global Accuracy: {(TP + TN) / (TP + FP + TN + FN) * 100:.2f}%\")\n",
    "\n",
    "# Construct a fake y_true and y_pred to match sklearn's classification_report format\n",
    "y_true = np.array([1] * TP + [0] * TN + [1] * FN + [0] * FP)  # True labels\n",
    "y_pred = np.array([1] * TP + [0] * TN + [0] * FN + [1] * FP)  # Predicted labels\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_true, y_pred, target_names=['ATTACK', 'BENIGN'], digits=4) # reverse labels because classification_report assumes first label is 0\n",
    "print(report)\n",
    "\n",
    "print(f\"True Negative Rate: {TN/(TN+FP)*100:.2f}%\")\n",
    "print(f\"False Positive Rate: {FP/(TN+FP)*100:.2f}%\")\n",
    "print(f\"True Positive Rate: {TP/(TP+FN)*100:.2f}%\")\n",
    "print(f\"False Negative Rate: {FN/(TP+FN)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Attack-Samples: 1000\n",
      "Predicted indices: 1000\n",
      "Predicted Normal indices: 1000\n",
      "Normal Misclassified indices: 0\n",
      "ADV Detection Rate: 1.0000\n",
      "Misclassification Rate: 0.0000\n"
     ]
    }
   ],
   "source": [
    "sample_indices = y_pred_eval_detector.index\n",
    "print(f\"#Attack-Samples: {len(sample_indices)}\")\n",
    "\n",
    "detected_indices = np.unique(np.concatenate((pred_class_0, pred_class_1)))\n",
    "print(f\"Predicted indices: {len(detected_indices)}\")\n",
    "\n",
    "correct_benign_pred_indices = np.intersect1d(sample_indices, detected_indices)\n",
    "print(f\"Predicted Normal indices: {len(correct_benign_pred_indices)}\")\n",
    "\n",
    "normal_benign_misclassified_indices = np.setdiff1d(sample_indices, detected_indices)\n",
    "print(f\"Normal Misclassified indices: {len(normal_benign_misclassified_indices)}\")\n",
    "\n",
    "print(f\"ADV Detection Rate: {len(correct_benign_pred_indices) / len(sample_indices):.4f}\")\n",
    "print(f\"Misclassification Rate: {len(normal_benign_misclassified_indices) / len(sample_indices):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
