{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototype: kappa\n",
    "\n",
    "| Properties      | Data    |\n",
    "|---------------|-----------|\n",
    "| *Labels* | `['BENIGN', 'DDoS']` |\n",
    "| *Normalization* | `Min-Max` |\n",
    "| *Sample Size* | `40.000`|\n",
    "| *Adversarial Attack* | `FGSM & C&W & JSMA & PGD` |\n",
    "| *Explanations* | `SHAP` |\n",
    "| *Detector* | `Detect Attacks and Misclassified Samples` |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Has to be run first alone!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To import modules from the functions directory\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Building CICIDS2017 dataset --\n",
      "--- Combining all CICIDS2017 files ---\n",
      "Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\n",
      "Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\n",
      "Tuesday-WorkingHours.pcap_ISCX.csv\n",
      "Wednesday-workingHours.pcap_ISCX.csv\n",
      "Friday-WorkingHours-Morning.pcap_ISCX.csv\n",
      "Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\n",
      "Monday-WorkingHours.pcap_ISCX.csv\n",
      "Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\n",
      "--- Removing NaN and Infinity values ---\n",
      "Removing 1358 Rows with NaN values\n",
      "Removing 1509 Rows with Infinity values\n",
      "--- Extracting labels ---\n",
      " Label\n",
      "BENIGN    2271320\n",
      "DDoS       128025\n",
      "Name: count, dtype: int64\n",
      "-- Generating normalizer --\n",
      "--- Splitting labels and features ---\n",
      "Zero Columns: [' Bwd PSH Flags', ' Bwd URG Flags', 'Fwd Avg Bytes/Bulk', ' Fwd Avg Packets/Bulk', ' Fwd Avg Bulk Rate', ' Bwd Avg Bytes/Bulk', ' Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate']\n",
      "-- Preprocessing data --\n",
      "--- Sampling balanced data ---\n",
      "Sample to shape: (40000, 79)\n",
      "--- Splitting labels and features ---\n",
      "--- Encoding labels as binary one-hot values ---\n",
      "--- Normalizing features using MinMaxScaler ---\n",
      "Generate Features | Indices: Index([1787989, 978677, 500719, 1942857, 2150382], dtype='int64')... | Shape: (40000, 70)\n",
      "Generate Labels | Indices: Index([1787989, 978677, 500719, 1942857, 2150382], dtype='int64')... | Shape: (40000, 2)\n",
      "BENIGN  ATTACK\n",
      "False   True      20000\n",
      "True    False     20000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import functions.data_preprocessing as dp\n",
    "import importlib\n",
    "importlib.reload(dp)\n",
    "\n",
    "encoding_type = 0 # binary encoding\n",
    "norm_type = 0 # min-max normalization\n",
    "label_names = ['BENIGN', 'DDoS'] # labels to include\n",
    "sample_size = 20000 # sample size for each label -> 2 x sample_size = total samples\n",
    "\n",
    "dataset = dp.build_dataset(label_names)\n",
    "\n",
    "normalizer, zero_columns = dp.generate_normalizer(dataset, norm_type)\n",
    "\n",
    "feature_df, label_df, used_indices = dp.preprocess_data(dataset, encoding_type, normalizer, zero_columns, sample_size=sample_size, random_sample_state=42)\n",
    "print(f\"Generate Features | Indices: {feature_df.index[:5]}... | Shape: {feature_df.shape}\")\n",
    "print(f\"Generate Labels | Indices: {label_df.index[:5]}... | Shape: {label_df.shape}\")\n",
    "print(label_df.value_counts()) # -> will first show [0, 1] then [1, 0] if label number is equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32000, 70) (8000, 70) (32000, 2) (8000, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_df, label_df, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9127 - loss: 0.3673 - val_accuracy: 0.9806 - val_loss: 0.0486\n",
      "Epoch 2/10\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - accuracy: 0.9833 - loss: 0.0428 - val_accuracy: 0.9822 - val_loss: 0.0357\n",
      "Epoch 3/10\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - accuracy: 0.9869 - loss: 0.0317 - val_accuracy: 0.9834 - val_loss: 0.0303\n",
      "Epoch 4/10\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - accuracy: 0.9875 - loss: 0.0266 - val_accuracy: 0.9837 - val_loss: 0.0275\n",
      "Epoch 5/10\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - accuracy: 0.9896 - loss: 0.0240 - val_accuracy: 0.9850 - val_loss: 0.0254\n",
      "Epoch 6/10\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - accuracy: 0.9897 - loss: 0.0221 - val_accuracy: 0.9873 - val_loss: 0.0234\n",
      "Epoch 7/10\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - accuracy: 0.9903 - loss: 0.0206 - val_accuracy: 0.9889 - val_loss: 0.0221\n",
      "Epoch 8/10\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - accuracy: 0.9908 - loss: 0.0199 - val_accuracy: 0.9903 - val_loss: 0.0212\n",
      "Epoch 9/10\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - accuracy: 0.9915 - loss: 0.0186 - val_accuracy: 0.9919 - val_loss: 0.0202\n",
      "Epoch 10/10\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - accuracy: 0.9920 - loss: 0.0178 - val_accuracy: 0.9919 - val_loss: 0.0198\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step\n",
      "Global Accuracy: 99.12%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ATTACK     0.9842    0.9985    0.9913      3986\n",
      "      BENIGN     0.9985    0.9841    0.9912      4014\n",
      "\n",
      "    accuracy                         0.9912      8000\n",
      "   macro avg     0.9913    0.9913    0.9912      8000\n",
      "weighted avg     0.9914    0.9912    0.9912      8000\n",
      "\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342us/step\n",
      "Predictions on Normal Data | Indices: Index([604721, 1807601, 2213979, 761448, 331372], dtype='int64')... | Shape: (32000, 2)\n"
     ]
    }
   ],
   "source": [
    "import functions.intrusion_detection_system as ids\n",
    "import importlib\n",
    "importlib.reload(ids)\n",
    "\n",
    "# TODO: build ids with complete dataset\n",
    "# X_train_all, y_train_all, _ = dp.preprocess_data(dataset, encoding_type, normalizer, zero_columns, random_sample_state=42)\n",
    "# print(y_train_all.value_counts())\n",
    "# X_train_all, X_test_all, y_train_all, y_test_all = train_test_split(X_train_all, y_train_all, test_size=0.2, random_state=42)\n",
    "# print(X_train_all.shape, X_test_all.shape, y_train_all.shape, y_test_all.shape)\n",
    "\n",
    "# build ids and evaluate it on test data\n",
    "ids_model = ids.build_intrusion_detection_system(X_train, y_train, X_test, y_test)\n",
    "# store prediction from X_train\n",
    "y_pred = ids.predict(ids_model, X_train, columns=y_train.columns)\n",
    "print(f\"Predictions on Normal Data | Indices: {y_pred.index[:5]}... | Shape: {y_pred.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Adversarial Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "def split_into_classes(X, y, class_labels):\n",
    "    \"\"\"\n",
    "    Splits the dataset evenly into specified classes with given labels.\n",
    "\n",
    "    Args:\n",
    "        X (numpy.ndarray): The input samples.\n",
    "        y (numpy.ndarray): The labels.\n",
    "        class_labels (list of str): The names of the classes (e.g., [\"normal\", \"cw\", \"fgsm\", \"hsj\"]).\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are class names and values are tuples (X_subset, y_subset).\n",
    "    \"\"\"\n",
    "    num_classes = len(class_labels)\n",
    "\n",
    "    if len(X) % num_classes != 0:\n",
    "        raise ValueError(\"Number of samples must be evenly divisible by the number of classes.\")\n",
    "\n",
    "    # Shuffle data to avoid biases\n",
    "    X, y = shuffle(X, y, random_state=42)\n",
    "\n",
    "    # Compute samples per class\n",
    "    num_samples_per_class = len(X) // num_classes\n",
    "\n",
    "    # Dictionary to store the split datasets\n",
    "    class_splits = {}\n",
    "\n",
    "    for i, label in enumerate(class_labels):\n",
    "        start = i * num_samples_per_class\n",
    "        end = (i + 1) * num_samples_per_class\n",
    "        class_splits[label] = (X[start:end], y[start:end])\n",
    "\n",
    "    return class_splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b25a7f2ef444a82a7eac4b768900879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "JSMA:   0%|          | 0/6400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial JSMA examples generated. Shape: (6400, 70)\n",
      "Create JSMA Adversarial Attack | Indices: Index([79319, 1836822, 1340447, 477738, 1361834], dtype='int64')... | Shape: (6400, 70)\n",
      "Accuracy: 50.98%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ATTACK     0.0000    0.0000    0.0000      3137\n",
      "      BENIGN     0.5098    1.0000    0.6754      3263\n",
      "\n",
      "    accuracy                         0.5098      6400\n",
      "   macro avg     0.2549    0.5000    0.3377      6400\n",
      "weighted avg     0.2599    0.5098    0.3443      6400\n",
      "\n",
      "Confusion Matrix: Positive == BENIGN\n",
      "TN: 0, FP: 3137, FN: 0, TP: 3263\n",
      "Predictions on Adversarial Attacks | Indices: Index([79319, 1836822, 1340447, 477738, 1361834], dtype='int64')... | Shape: (6400, 2)\n"
     ]
    }
   ],
   "source": [
    "import functions.attack_generator as ag\n",
    "import importlib\n",
    "import numpy as np\n",
    "importlib.reload(ag)\n",
    "\n",
    "all_features = dataset.drop(columns=[' Label'])\n",
    "art_model = ag.convert_to_art_model(ids_model, X_train) # TODO: use all features for generating art model\n",
    "\n",
    "# Split the training data into classes\n",
    "class_labels = [\"normal\", \"cw\", \"fgsm\", \"jsma\", \"pgd\"]  # Change this to any class names\n",
    "splits = split_into_classes(X_train, y_train, class_labels)\n",
    "X_normal, y_normal = splits[\"normal\"]\n",
    "X_cw, y_cw = splits[\"cw\"]\n",
    "X_fgsm, y_fgsm = splits[\"fgsm\"]\n",
    "X_jsma, y_jsma = splits[\"jsma\"]\n",
    "X_pgd, y_pgd = splits[\"pgd\"]\n",
    "print(f\"Normal Data: {X_normal.shape} | CW Data: {X_cw.shape} | FGSM Data: {X_fgsm.shape} | JSMA Data: {X_jsma.shape} | PGD Data: {X_pgd.shape}\")\n",
    "\n",
    "# generate attacks on the separated training data\n",
    "# TODO: when changing epsilon, the detector accuracy rises\n",
    "X_adv_fgsm = ag.generate_fgsm_attacks(art_model, X_fgsm, target_label=1)\n",
    "print(f\"Create FGSM Adversarial Attack | Indices: {X_adv_fgsm.index[:5]}... | Shape: {X_adv_fgsm.shape}\")\n",
    "y_pred_adv_fgsm = ag.evaluate_art_model(art_model, X_adv_fgsm, y_fgsm)\n",
    "print(f\"Predictions on Adversarial Attacks | Indices: {y_pred_adv_fgsm.index[:5]}... | Shape: {y_pred_adv_fgsm.shape}\")\n",
    "y_pred_fgsm = y_pred.loc[X_fgsm.index]\n",
    "\n",
    "import multiprocessing\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "X_adv_cw = ag.generate_cw_attacks_parallel(art_model, X_cw, target_label=1, num_cores=num_cores)\n",
    "print(f\"Create CW Adversarial Attack | Indices: {X_adv_cw.index[:5]}... | Shape: {X_adv_cw.shape}\")\n",
    "y_pred_adv_cw = ag.evaluate_art_model(art_model, X_adv_cw, y_cw)\n",
    "print(f\"Predictions on Adversarial Attacks | Indices: {y_pred_adv_cw.index[:5]}... | Shape: {y_pred_adv_cw.shape}\")\n",
    "y_pred_cw = y_pred.loc[X_cw.index]\n",
    "\n",
    "X_adv_jsma = ag.generate_jsma_attacks(art_model, X_jsma, target_label=1)\n",
    "print(f\"Create JSMA Adversarial Attack | Indices: {X_adv_jsma.index[:5]}... | Shape: {X_adv_jsma.shape}\")\n",
    "y_pred_adv_jsma = ag.evaluate_art_model(art_model, X_adv_jsma, y_jsma)\n",
    "print(f\"Predictions on Adversarial Attacks | Indices: {y_pred_adv_jsma.index[:5]}... | Shape: {y_pred_adv_jsma.shape}\")\n",
    "y_pred_jsma = y_pred.loc[X_jsma.index]\n",
    "\n",
    "X_adv_pgd = ag.generate_pgd_attacks(art_model, X_pgd, target_label=1)\n",
    "print(f\"Create HSJ Adversarial Attack | Indices: {X_adv_pgd.index[:5]}... | Shape: {X_adv_pgd.shape}\")\n",
    "y_pred_adv_pgd = ag.evaluate_art_model(art_model, X_adv_pgd, y_pgd)\n",
    "print(f\"Predictions on Adversarial Attacks | Indices: {y_pred_adv_pgd.index[:5]}... | Shape: {y_pred_adv_pgd.shape}\")\n",
    "y_pred_pgd = y_pred.loc[X_pgd.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correctly_benign_classified_indices(y_train, y_pred):\n",
    "    benign_indices = y_train[y_train['BENIGN'] == 1].index\n",
    "    benign_adv_predicted_indices = y_pred[y_pred['BENIGN'] == 1].index\n",
    "    correctly_benign_classified_indices = benign_indices.intersection(benign_adv_predicted_indices)\n",
    "    return correctly_benign_classified_indices\n",
    "\n",
    "def get_misclassified_as_benign_due_attack_indices(y_train, y_pred, y_pred_adv):\n",
    "    attack_indices = y_train[y_train['ATTACK'] == 1].index\n",
    "    attack_adv_predicted_indices = y_pred[y_pred['ATTACK'] == 1].index\n",
    "    benign_predicted_adversarial_indices = y_pred_adv[y_pred_adv['BENIGN'] == 1].index\n",
    "    misclassified_as_benign_due_attack_indices = attack_indices.intersection(attack_adv_predicted_indices).intersection(benign_predicted_adversarial_indices)\n",
    "    return misclassified_as_benign_due_attack_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly classified as BENIGN from the IDS: 3085 | Indices: Index([606504, 2655053, 820505], dtype='int64')\n",
      "    Correctly classified as BENIGN from the IDS (FGSM): 3159 | Indices: Index([281272, 443688, 2048428], dtype='int64')\n",
      "    ATTACK sample misclassified as BENIGN due to adversarial attack (FGSM): 3237 | Indices: Index([414312, 450214, 428606], dtype='int64')\n",
      "        Correctly classified as BENIGN from the IDS (CW): 3185 | Indices: Index([1806823, 706236, 1671681], dtype='int64')\n",
      "        ATTACK sample misclassified as BENIGN due to adversarial attack (CW): 1509 | Indices: Index([367524, 403889, 475346], dtype='int64')\n",
      "            Correctly classified as BENIGN from the IDS (PGD): 3158 | Indices: Index([2032524, 2720032, 979762], dtype='int64')\n",
      "            ATTACK sample misclassified as BENIGN due to adversarial attack (PGD): 3193 | Indices: Index([359920, 410469, 440128], dtype='int64')\n",
      "                Correctly classified as BENIGN from the IDS (JSMA): 3214 | Indices: Index([79319, 1836822, 1340447], dtype='int64')\n",
      "                ATTACK sample misclassified as BENIGN due to adversarial attack (JSMA): 3132 | Indices: Index([477738, 324326, 353511], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "y_pred_normal = y_pred.loc[X_normal.index]\n",
    "correctly_benign_classified_indices = get_correctly_benign_classified_indices(y_normal, y_pred_normal)\n",
    "\n",
    "correctly_benign_classified_indices_fgsm = get_correctly_benign_classified_indices(y_fgsm, y_pred_adv_fgsm)\n",
    "misclassified_as_benign_due_attack_indices_fgsm = get_misclassified_as_benign_due_attack_indices(y_fgsm, y_pred_fgsm, y_pred_adv_fgsm)\n",
    "\n",
    "correctly_benign_classified_indices_cw = get_correctly_benign_classified_indices(y_cw, y_pred_cw)\n",
    "misclassified_as_benign_due_attack_indices_cw = get_misclassified_as_benign_due_attack_indices(y_cw, y_pred_cw, y_pred_adv_cw)\n",
    "\n",
    "correctly_benign_classified_indices_jsma = get_correctly_benign_classified_indices(y_jsma, y_pred_jsma)\n",
    "misclassified_as_benign_due_attack_indices_jsma = get_misclassified_as_benign_due_attack_indices(y_jsma, y_pred_jsma, y_pred_adv_jsma)\n",
    "\n",
    "# TODO: is it correct to only include the samples that are correctly classified from the IDS?\n",
    "correctly_benign_classified_indices_pgd = get_correctly_benign_classified_indices(y_pgd, y_pred_pgd)\n",
    "misclassified_as_benign_due_attack_indices_pgd = get_misclassified_as_benign_due_attack_indices(y_pgd, y_pred_pgd, y_pred_adv_pgd)\n",
    "\n",
    "print(f\"Correctly classified as BENIGN from the IDS: {len(correctly_benign_classified_indices)} | Indices: {correctly_benign_classified_indices[:3]}\")\n",
    "print(f\"    Correctly classified as BENIGN from the IDS (FGSM): {len(correctly_benign_classified_indices_fgsm)} | Indices: {correctly_benign_classified_indices_fgsm[:3]}\")\n",
    "print(f\"    ATTACK sample misclassified as BENIGN due to adversarial attack (FGSM): {len(misclassified_as_benign_due_attack_indices_fgsm)} | Indices: {misclassified_as_benign_due_attack_indices_fgsm[:3]}\")\n",
    "print(f\"        Correctly classified as BENIGN from the IDS (CW): {len(correctly_benign_classified_indices_cw)} | Indices: {correctly_benign_classified_indices_cw[:3]}\")\n",
    "print(f\"        ATTACK sample misclassified as BENIGN due to adversarial attack (CW): {len(misclassified_as_benign_due_attack_indices_cw)} | Indices: {misclassified_as_benign_due_attack_indices_cw[:3]}\")\n",
    "print(f\"            Correctly classified as BENIGN from the IDS (PGD): {len(correctly_benign_classified_indices_pgd)} | Indices: {correctly_benign_classified_indices_pgd[:3]}\")\n",
    "print(f\"            ATTACK sample misclassified as BENIGN due to adversarial attack (PGD): {len(misclassified_as_benign_due_attack_indices_pgd)} | Indices: {misclassified_as_benign_due_attack_indices_pgd[:3]}\")\n",
    "print(f\"                Correctly classified as BENIGN from the IDS (JSMA): {len(correctly_benign_classified_indices_jsma)} | Indices: {correctly_benign_classified_indices_jsma[:3]}\")\n",
    "print(f\"                ATTACK sample misclassified as BENIGN due to adversarial attack (JSMA): {len(misclassified_as_benign_due_attack_indices_jsma)} | Indices: {misclassified_as_benign_due_attack_indices_jsma[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions.visualizer as visualizer\n",
    "# import importlib\n",
    "# importlib.reload(visualizer)\n",
    "\n",
    "# visualizer.visualize_data_distribution(X_train.loc[correctly_benign_classified_indices], 'Normal Data', X_adv_fgsm.loc[misclassified_as_benign_due_attack_indices_fgsm], 'Adversarial Data')\n",
    "# # visualizer.visualize_data_distribution(X_train.loc[misclassified_as_benign_due_attack_indices], 'Normal Data', X_adv.loc[misclassified_as_benign_due_attack_indices], 'Adversarial Data', side_by_side=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PermutationExplainer explainer: 6401it [03:22, 29.98it/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate JSMA Adversarial Explanations | Indices: Index([79319, 1836822, 1340447, 477738, 1361834], dtype='int64')... | Shape: (6400, 70)\n"
     ]
    }
   ],
   "source": [
    "import functions.explainer as exp\n",
    "import importlib\n",
    "importlib.reload(exp)\n",
    "\n",
    "explainer = exp.generate_shap_explainer(ids_model, X_train)\n",
    "\n",
    "shap_values_df = exp.generate_shap_values(explainer, X_normal)\n",
    "print(f\"Generate Explanations | Indices: {shap_values_df.index[:5]}... | Shape: {shap_values_df.shape}\")\n",
    "\n",
    "shap_values_adv_df_fgsm = exp.generate_shap_values(explainer, X_adv_fgsm)\n",
    "print(f\"Generate FGSM Adversarial Explanations | Indices: {shap_values_adv_df_fgsm.index[:5]}... | Shape: {shap_values_adv_df_fgsm.shape}\")\n",
    "\n",
    "shap_values_adv_df_cw = exp.generate_shap_values(explainer, X_adv_cw)\n",
    "print(f\"Generate CW Adversarial Explanations | Indices: {shap_values_adv_df_cw.index[:5]}... | Shape: {shap_values_adv_df_cw.shape}\")\n",
    "\n",
    "shap_values_adv_df_jsma = exp.generate_shap_values(explainer, X_adv_jsma)\n",
    "print(f\"Generate JSMA Adversarial Explanations | Indices: {shap_values_adv_df_jsma.index[:5]}... | Shape: {shap_values_adv_df_jsma.shape}\")\n",
    "\n",
    "shap_values_adv_df_pgd = exp.generate_shap_values(explainer, X_adv_pgd)\n",
    "print(f\"Generate PGD Adversarial Explanations | Indices: {shap_values_adv_df_pgd.index[:5]}... | Shape: {shap_values_adv_df_pgd.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# # concat_correctly_benign_classified_shaps = pd.concat([shap_values_df.loc[correctly_benign_classified_indices], shap_values_adv_df_fgsm.loc[correctly_benign_classified_indices_fgsm], shap_values_adv_df_cw.loc[correctly_benign_classified_indices_cw]], axis=0)\n",
    "# # # shap_values_df.loc[misclassified_as_benign_due_attack_indices]\n",
    "# # concat_misclassified_as_benign_shaps = pd.concat([shap_values_adv_df_fgsm.loc[misclassified_as_benign_due_attack_indices_fgsm], shap_values_adv_df_cw.loc[misclassified_as_benign_due_attack_indices_cw]], axis=0)\n",
    "\n",
    "# concat_correctly_benign_classified_shaps = pd.concat([shap_values_df.loc[correctly_benign_classified_indices], shap_values_adv_df_fgsm.loc[correctly_benign_classified_indices_fgsm]], axis=0)\n",
    "# # shap_values_df.loc[misclassified_as_benign_due_attack_indices]\n",
    "# concat_misclassified_as_benign_shaps = pd.concat([shap_values_adv_df_fgsm.loc[misclassified_as_benign_due_attack_indices_fgsm]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions.visualizer as visualizer\n",
    "# import importlib\n",
    "# importlib.reload(visualizer)\n",
    "\n",
    "# visualizer.visualize_data_distribution(shap_values_df.loc[correctly_benign_classified_indices], 'Normal Explanations', shap_values_adv_df_fgsm.loc[misclassified_as_benign_due_attack_indices_fgsm], 'Adversarial Explanations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp.plot_shap_summary_comparison(shap_values_df.loc[correctly_benign_classified_indices].values, X_train.loc[correctly_benign_classified_indices], shap_values_adv_df.loc[misclassified_as_benign_due_attack_indices].values, X_adv.loc[misclassified_as_benign_due_attack_indices], 6, title='Normal vs Adversarial Explanations of Benign Samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adversarial_correct_benign_indices_cw = correctly_benign_classified_indices_cw\n",
    "# adversarial_misclassified_as_benign_indices_cw = misclassified_as_benign_due_attack_indices_cw\n",
    "# adversarial_correct_benign_indices_fgsm = correctly_benign_classified_indices_fgsm\n",
    "# adversarial_misclassified_as_benign_indices_fgsm = misclassified_as_benign_due_attack_indices_fgsm\n",
    "# normal_correct_benign_indices = correctly_benign_classified_indices\n",
    "\n",
    "# attack_indices = y_normal[y_normal['ATTACK'] == 1].index\n",
    "# predicted_benign_indices = y_pred_normal[y_pred_normal['BENIGN'] == 1].index\n",
    "# normal_misclassified_as_benign_indices = attack_indices.intersection(predicted_benign_indices)\n",
    "\n",
    "# print(f\"Normal Correctly Classified as Benign: {len(normal_correct_benign_indices)}\")\n",
    "# print(f\"Normal Misclassified as Benign: {len(normal_misclassified_as_benign_indices)}\")\n",
    "# print(f\"Adversarial Correctly Classified as Benign (CW): {len(adversarial_correct_benign_indices_cw)}\")\n",
    "# print(f\"Adversarial Misclassified as Benign (CW): {len(adversarial_misclassified_as_benign_indices_cw)}\")\n",
    "# print(f\"Adversarial Correctly Classified as Benign (FGSM): {len(adversarial_correct_benign_indices_fgsm)}\")\n",
    "# print(f\"Adversarial Misclassified as Benign (FGSM): {len(adversarial_misclassified_as_benign_indices_fgsm)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataset(class_samples):\n",
    "    \"\"\"\n",
    "    Create dataset from given class samples while preserving the original indices.\n",
    "    \n",
    "    Args:\n",
    "        class_samples (dict): Dictionary where keys are class names and values are DataFrames of samples.\n",
    "    \n",
    "    Returns:\n",
    "        X (pd.DataFrame): Feature matrix with original indices retained.\n",
    "        y (pd.DataFrame): One-hot encoded labels with corresponding indices.\n",
    "    \"\"\"\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    \n",
    "    class_labels = list(class_samples.keys())\n",
    "    num_classes = len(class_labels)\n",
    "    \n",
    "    for i, class_name in enumerate(class_labels):\n",
    "        samples = class_samples[class_name]\n",
    "\n",
    "        # Create one-hot encoding for the class\n",
    "        one_hot = np.zeros((samples.shape[0], num_classes))\n",
    "        one_hot[:, i] = 1  \n",
    "        \n",
    "        X_list.append(samples)\n",
    "        \n",
    "        # Convert one-hot encoding to DataFrame with matching indices\n",
    "        y_df = pd.DataFrame(one_hot, index=samples.index, columns=class_labels)\n",
    "        y_list.append(y_df)\n",
    "    \n",
    "    # Concatenate all selected samples\n",
    "    X = pd.concat(X_list, axis=0)\n",
    "    y = pd.concat(y_list, axis=0)\n",
    "\n",
    "    print(f\"Generated dataset: X shape {X.shape}, y shape {y.shape}\")\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "adv_concat_correctly_benign_classified_shaps = pd.concat([\n",
    "    shap_values_adv_df_fgsm.loc[correctly_benign_classified_indices_fgsm],\n",
    "    shap_values_adv_df_pgd.loc[correctly_benign_classified_indices_pgd],\n",
    "    ], axis=0)\n",
    "# shap_values_df.loc[misclassified_as_benign_due_attack_indices]\n",
    "adv_concat_misclassified_as_benign_shaps = pd.concat([\n",
    "    shap_values_adv_df_fgsm.loc[misclassified_as_benign_due_attack_indices_fgsm], \n",
    "    shap_values_adv_df_pgd.loc[misclassified_as_benign_due_attack_indices_pgd],\n",
    "    ], axis=0)\n",
    "\n",
    "concat_correct_benign_shaps = pd.concat([\n",
    "    shap_values_df.loc[correctly_benign_classified_indices], \n",
    "    shap_values_adv_df_cw.loc[correctly_benign_classified_indices_cw],\n",
    "    shap_values_adv_df_jsma.loc[correctly_benign_classified_indices_jsma],\n",
    "    ], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated dataset: X shape (26872, 70), y shape (26872, 5)\n",
      "(26872, 70) (26872, 5)\n"
     ]
    }
   ],
   "source": [
    "class_samples = {\n",
    "    'ADV CORRECT BENIGN': adv_concat_correctly_benign_classified_shaps,\n",
    "    'ADV MISCLASSIFIED': adv_concat_misclassified_as_benign_shaps,\n",
    "    'CW MISCLASSIFIED': shap_values_adv_df_cw.loc[misclassified_as_benign_due_attack_indices_cw],\n",
    "    'JSMA MISCLASSIFIED': shap_values_adv_df_jsma.loc[misclassified_as_benign_due_attack_indices_jsma],\n",
    "    'CORRECT BENIGN': concat_correct_benign_shaps, \n",
    "}\n",
    "\n",
    "X, y = create_dataset(class_samples)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26872, 70) (26872, 5)\n",
      "(24184, 70) (2688, 70) (24184, 5) (2688, 5)\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 14:32:38.938493: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4506 - loss: 1.3877 - val_accuracy: 0.8888 - val_loss: 0.4615\n",
      "Epoch 2/10\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8035 - loss: 0.4986 - val_accuracy: 0.9086 - val_loss: 0.2481\n",
      "Epoch 3/10\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8670 - loss: 0.3375 - val_accuracy: 0.9221 - val_loss: 0.1959\n",
      "Epoch 4/10\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8882 - loss: 0.2781 - val_accuracy: 0.9281 - val_loss: 0.1762\n",
      "Epoch 5/10\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9076 - loss: 0.2409 - val_accuracy: 0.9349 - val_loss: 0.1592\n",
      "Epoch 6/10\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9166 - loss: 0.2188 - val_accuracy: 0.9403 - val_loss: 0.1497\n",
      "Epoch 7/10\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9229 - loss: 0.2077 - val_accuracy: 0.9440 - val_loss: 0.1398\n",
      "Epoch 8/10\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9282 - loss: 0.1901 - val_accuracy: 0.9485 - val_loss: 0.1314\n",
      "Epoch 9/10\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9296 - loss: 0.1893 - val_accuracy: 0.9518 - val_loss: 0.1259\n",
      "Epoch 10/10\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9369 - loss: 0.1675 - val_accuracy: 0.9547 - val_loss: 0.1203\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step\n"
     ]
    }
   ],
   "source": [
    "import functions.detector as det\n",
    "import importlib\n",
    "importlib.reload(det)\n",
    "\n",
    "# build detector to detect adversarial samples that misclassify attack samples as benign\n",
    "\n",
    "# create dataframe\n",
    "# TODO: build detector with normal and adversarial shap values?\n",
    "# TODO: build with shap_values_adv_df to detect 'BENIGN' and 'ATTACK'\n",
    "import pandas as pd\n",
    "\n",
    "# alternative approach: detector that predicts the original label of the sample for all given adversarial attacks\n",
    "# concat_correctly_benign_classified_shaps = pd.concat([shap_values_df.loc[correctly_benign_classified_indices], shap_values_adv_df.loc[correctly_benign_classified_indices]], axis=0)\n",
    "# concat_misclassified_as_benign_shaps = pd.concat([shap_values_df.loc[misclassified_as_benign_due_attack_indices], shap_values_adv_df.loc[misclassified_as_benign_due_attack_indices]], axis=0)\n",
    "# X, y = det.build_train_datasets(shap_values_df.loc[correctly_benign_classified_indices], shap_values_adv_df_fgsm.loc[misclassified_as_benign_due_attack_indices_fgsm])\n",
    "\n",
    "#X, y = det.build_train_datasets(shap_values_df.loc[correctly_benign_classified_indices], shap_values_adv_df.loc[misclassified_as_benign_due_attack_indices])\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "# split data\n",
    "X_train_det, X_test_det, y_train_det, y_test_det = train_test_split(X, y, test_size=0.1, random_state=1503)\n",
    "print(X_train_det.shape, X_test_det.shape, y_train_det.shape, y_test_det.shape)\n",
    "\n",
    "# build detector\n",
    "detector = det.build_detector(X_train_det, y_train_det, X_test_det, y_test_det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/84\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 16ms/step"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step\n",
      "Predictions on Detector | Indices: Index([1780284, 386694, 677502, 467834, 2268119], dtype='int64')... | Shape: (2688, 5)\n",
      "[4 3 4 2 0] [4 3 4 2 0]\n",
      "Overall Accuracy: 0.9475\n",
      "Classification Report (Overall):\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "ADV CORRECT BENIGN       0.87      0.95      0.91       641\n",
      " ADV MISCLASSIFIED       0.95      0.86      0.90       642\n",
      "  CW MISCLASSIFIED       0.97      0.94      0.95       156\n",
      "JSMA MISCLASSIFIED       1.00      1.00      1.00       310\n",
      "    CORRECT BENIGN       0.99      0.99      0.99       939\n",
      "\n",
      "          accuracy                           0.95      2688\n",
      "         macro avg       0.95      0.95      0.95      2688\n",
      "      weighted avg       0.95      0.95      0.95      2688\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate detector\n",
    "y_pred_det = det.predict(detector, X_test_det, y.columns)\n",
    "print(f\"Predictions on Detector | Indices: {y_pred_det.index[:5]}... | Shape: {y_pred_det.shape}\")\n",
    "\n",
    "# Convert one-hot to class indices\n",
    "y_true_indices = np.argmax(y_test_det, axis=1)\n",
    "y_true_indices_pd = pd.Series(y_true_indices, index=y_test_det.index)\n",
    "y_pred_indices = np.argmax(y_pred_det, axis=1)\n",
    "y_pred_indices_pd = pd.Series(y_pred_indices, index=y_pred_det.index)\n",
    "print(y_true_indices[:5], y_pred_indices[:5])\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Compute Accuracy\n",
    "accuracy = accuracy_score(y_true_indices, y_pred_indices)\n",
    "print(f\"Overall Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Compute Classification Report for overall classification\n",
    "print(\"Classification Report (Overall):\")\n",
    "print(classification_report(y_true_indices, y_pred_indices, target_names=y.columns, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get unique values and their counts\n",
    "# values, counts = np.unique(y_pred_indices, return_counts=True)\n",
    "\n",
    "# # Combine values and counts into a dictionary or print\n",
    "# value_counts = dict(zip(values, counts))\n",
    "# print(value_counts)\n",
    "\n",
    "# norm_benign_indices = y_test_det[y_test_det['NORM BENIGN'] == 1].index\n",
    "# print(f\"Normal Benign Indices: {len(norm_benign_indices)}\")\n",
    "\n",
    "# print(y_pred_indices_pd[norm_benign_indices].value_counts())\n",
    "\n",
    "# # 0 == FGSM CORRECT BENIGN, 1 == FGSM MISCLASSIFIED, 2 == CW CORRECT BENIGN, 3 == CW MISCLASSIFIED, 4 == NORM BENIGN\n",
    "# norm_pred_benign_indices = y_pred_indices_pd[y_pred_indices_pd == 4].index\n",
    "# print(f\"Normal Predicted Benign Indices: {len(norm_pred_benign_indices)}\")\n",
    "\n",
    "# norm_pred_cw_correct_benign_indices = y_pred_indices_pd[y_pred_indices_pd == 2].index\n",
    "# print(f\"Normal Predicted CW Correct Benign Indices: {len(norm_pred_cw_correct_benign_indices)}\")\n",
    "\n",
    "# benign_pred_indices = np.unique(np.concatenate((norm_pred_benign_indices, norm_pred_cw_correct_benign_indices)))\n",
    "\n",
    "# correct_benign_pred_indices = np.intersect1d(norm_benign_indices, benign_pred_indices)\n",
    "# print(f\"Predicted Normal indices: {len(correct_benign_pred_indices)}\")\n",
    "\n",
    "# normal_benign_misclassified_indices = np.setdiff1d(norm_benign_indices, benign_pred_indices)\n",
    "# print(f\"Normal Misclassified indices: {len(normal_benign_misclassified_indices)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fgsm_correct_bening_indices = y_test_det[y_test_det['FGSM CORRECT BENIGN'] == 1].index\n",
    "# print(f\"FGSM correct benign indices: {len(fgsm_correct_bening_indices)}\")\n",
    "# fgsm_misclassified_indices = y_test_det[y_test_det['FGSM MISCLASSIFIED'] == 1].index\n",
    "# print(f\"FGSM misclassified indices: {len(fgsm_misclassified_indices)}\")\n",
    "# fgsm_indices = np.unique(np.concatenate((fgsm_correct_bening_indices, fgsm_misclassified_indices)))\n",
    "# print(f\"FGSM indices: {len(fgsm_indices)}\")\n",
    "\n",
    "# fgsm_pred_correct_benign_indices = y_pred_det[y_pred_det['FGSM CORRECT BENIGN'] == True].index\n",
    "# print(f\"Predicted FGSM correct benign indices: {len(fgsm_pred_correct_benign_indices)}\")\n",
    "# fgsm_pred_misclassified_indices = y_pred_det[y_pred_det['FGSM MISCLASSIFIED'] == True].index\n",
    "# print(f\"Predicted FGSM misclassified indices: {len(fgsm_pred_misclassified_indices)}\")\n",
    "# fgsm_pred_indices = np.unique(np.concatenate((fgsm_pred_correct_benign_indices, fgsm_pred_misclassified_indices)))\n",
    "# print(f\"Predicted FGSM indices: {len(fgsm_pred_indices)}\")\n",
    "\n",
    "# fgsm_pred_indices = np.intersect1d(fgsm_indices, fgsm_pred_indices)\n",
    "# print(f\"Predicted FGSM indices: {len(fgsm_pred_indices)}\")\n",
    "\n",
    "# fgsm_misclassification_indices = np.setdiff1d(fgsm_indices, fgsm_pred_indices)\n",
    "# print(f\"FGSM misclassification indices: {len(fgsm_misclassification_indices)}\")\n",
    "\n",
    "\n",
    "# print(f\"FGSM Detection Rate: {len(fgsm_pred_indices) / len(fgsm_indices):.4f}\")\n",
    "# print(f\"Misclassification Rate: {len(fgsm_misclassification_indices) / len(fgsm_indices):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cw_correct_bening_indices = y_test_det[y_test_det['CW CORRECT BENIGN'] == 1].index\n",
    "# print(f\"CW correct benign indices: {len(fgsm_correct_bening_indices)}\")\n",
    "# cw_misclassified_indices = y_test_det[y_test_det['CW MISCLASSIFIED'] == 1].index\n",
    "# print(f\"CW misclassified indices: {len(cw_misclassified_indices)}\")\n",
    "# cw_indices = np.unique(np.concatenate((cw_correct_bening_indices, cw_misclassified_indices)))\n",
    "# print(f\"CW indices: {len(cw_indices)}\")\n",
    "\n",
    "# cw_pred_correct_benign_indices = y_pred_det[y_pred_det['CW CORRECT BENIGN'] == True].index\n",
    "# print(f\"Predicted CW correct benign indices: {len(cw_pred_correct_benign_indices)}\")\n",
    "# cw_pred_misclassified_indices = y_pred_det[y_pred_det['CW MISCLASSIFIED'] == True].index\n",
    "# print(f\"Predicted CW misclassified indices: {len(cw_pred_misclassified_indices)}\")\n",
    "# cw_pred_indices = np.unique(np.concatenate((cw_pred_correct_benign_indices, cw_pred_misclassified_indices)))\n",
    "# print(f\"Predicted CW indices: {len(cw_pred_indices)}\")\n",
    "\n",
    "# cw_pred_indices = np.intersect1d(cw_indices, cw_pred_indices)\n",
    "# print(f\"Predicted CW indices: {len(cw_pred_indices)}\")\n",
    "\n",
    "# cw_misclassification_indices = np.setdiff1d(cw_indices, cw_pred_indices)\n",
    "# print(f\"CW misclassification indices: {len(cw_misclassification_indices)}\")\n",
    "\n",
    "\n",
    "# print(f\"CW Detection Rate: {len(cw_pred_indices) / len(cw_indices):.4f}\")\n",
    "# print(f\"Misclassification Rate: {len(cw_misclassification_indices) / len(cw_indices):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_attack_detection(y_test_det, y_pred_det, attack_name):\n",
    "#     \"\"\"\n",
    "#     Evaluates the detection rate and misclassification rate for a given attack.\n",
    "    \n",
    "#     Parameters:\n",
    "#     - y_test_det: DataFrame containing true labels for attack detection.\n",
    "#     - y_pred_det: DataFrame containing predicted labels for attack detection.\n",
    "#     - attack_name: The name of the attack (e.g., 'FGSM', 'CW').\n",
    "    \n",
    "#     Returns:\n",
    "#     - A dictionary containing detection rate and misclassification rate.\n",
    "#     \"\"\"\n",
    "#     # Generate column names dynamically\n",
    "#     correct_benign_col = f\"{attack_name} CORRECT BENIGN\"\n",
    "#     misclassified_col = f\"{attack_name} MISCLASSIFIED\"\n",
    "    \n",
    "#     # Get indices for actual attack samples\n",
    "#     correct_benign_indices = y_test_det[y_test_det[correct_benign_col] == 1].index\n",
    "#     misclassified_indices = y_test_det[y_test_det[misclassified_col] == 1].index\n",
    "#     attack_indices = np.unique(np.concatenate((correct_benign_indices, misclassified_indices)))\n",
    "    \n",
    "#     print(f\"{attack_name} total samples: {len(attack_indices)}\")\n",
    "    \n",
    "#     # Get indices for predicted attack samples\n",
    "#     pred_correct_benign_indices = y_pred_det[y_pred_det[correct_benign_col] == True].index\n",
    "#     pred_misclassified_indices = y_pred_det[y_pred_det[misclassified_col] == True].index\n",
    "#     pred_attack_indices = np.unique(np.concatenate((pred_correct_benign_indices, pred_misclassified_indices)))\n",
    "    \n",
    "#     print(f\"Predicted {attack_name} total: {len(pred_attack_indices)}\")\n",
    "    \n",
    "#     # Find correctly detected attack samples\n",
    "#     detected_attack_indices = np.intersect1d(attack_indices, pred_attack_indices)\n",
    "#     print(f\"Correctly detected {attack_name} samples: {len(detected_attack_indices)}\")\n",
    "    \n",
    "#     # Find misclassified attack samples\n",
    "#     misclassified_attack_indices = np.setdiff1d(attack_indices, detected_attack_indices)\n",
    "#     print(f\"Misclassified {attack_name} samples: {len(misclassified_attack_indices)}\")\n",
    "    \n",
    "#     # Compute rates\n",
    "#     detection_rate = len(detected_attack_indices) / len(attack_indices) if len(attack_indices) > 0 else 0\n",
    "#     misclassification_rate = len(misclassified_attack_indices) / len(attack_indices) if len(attack_indices) > 0 else 0\n",
    "    \n",
    "#     print(f\"{attack_name} Detection Rate: {detection_rate:.4f}\")\n",
    "#     print(f\"{attack_name} Misclassification Rate: {misclassification_rate:.4f}\")\n",
    "    \n",
    "#     return {\n",
    "#         \"detection_rate\": detection_rate,\n",
    "#         \"misclassification_rate\": misclassification_rate\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = evaluate_attack_detection(y_test_det, y_pred_det, 'FGSM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Combine classes for adversarial detection (class 1 and class 2)\n",
    "# y_true_adv = np.where(np.isin(y_true_indices, [0, 1]), 1, 0)  # Adversarial = 1 (class 1 or 2), otherwise 0\n",
    "# y_pred_adv = np.where(np.isin(y_pred_indices, [0, 1]), 1, 0)  # Predicted as Adversarial\n",
    "# print(y_true_adv[:5], y_pred_adv[:5])\n",
    "\n",
    "# # Combine classes for benign detection (class 1 and class 3)\n",
    "# y_true_benign = np.where(np.isin(y_true_indices, [0, 2]), 1, 0)  # Benign = 1 (class 1 or 3), otherwise 0\n",
    "# y_pred_benign = np.where(np.isin(y_pred_indices, [0, 2]), 1, 0)  # Predicted as Benign\n",
    "# print(y_true_benign[:5], y_pred_benign[:5])\n",
    "\n",
    "\n",
    "# # Compute confusion matrix for Adversarial Detection\n",
    "# tn_adv, fp_adv, fn_adv, tp_adv = confusion_matrix(y_true_adv, y_pred_adv).ravel()\n",
    "# print(f\"\\nAdversarial Detection (Class 1 + 2):\")\n",
    "# print(f\"TP (Adversarial correctly detected): {tp_adv}\")\n",
    "# print(f\"FP (Benign incorrectly detected as adversarial): {fp_adv}\")\n",
    "# print(f\"TN (Benign correctly detected): {tn_adv}\")\n",
    "# print(f\"FN (Adversarial missed): {fn_adv}\")\n",
    "\n",
    "# # Calculate metrics for Adversarial Detection\n",
    "# tpr_adv = tp_adv / (tp_adv + fn_adv) if (tp_adv + fn_adv) != 0 else 0\n",
    "# fpr_adv = fp_adv / (fp_adv + tn_adv) if (fp_adv + tn_adv) != 0 else 0\n",
    "# fnr_adv = fn_adv / (tp_adv + fn_adv) if (tp_adv + fn_adv) != 0 else 0\n",
    "# tnr_adv = tn_adv / (tn_adv + fp_adv) if (tn_adv + fp_adv) != 0 else 0  \n",
    "\n",
    "# # Calculate accuracy for Adversarial Detection\n",
    "# accuracy_adv = (tp_adv + tn_adv) / (tp_adv + tn_adv + fp_adv + fn_adv) if (tp_adv + tn_adv + fp_adv + fn_adv) != 0 else 0\n",
    "\n",
    "# print(f\"Adversarial Detection Metrics:\")\n",
    "# print(f\"Adversarial Detection Accuracy: {100*accuracy_adv:.2f}%\")\n",
    "# print(f\"True Positive Rate (TPR): {100*tpr_adv:.2f}%\")\n",
    "# print(f\"False Positive Rate (FPR): {100*fpr_adv:.2f}%\")\n",
    "# print(f\"False Negative Rate (FNR): {100* fnr_adv:.2f}%\")\n",
    "# print(f\"True Negative Rate (TNR): {100*tnr_adv:.2f}%\") \n",
    "\n",
    "# # Compute confusion matrix for Benign Detection\n",
    "# tn_benign, fp_benign, fn_benign, tp_benign = confusion_matrix(y_true_benign, y_pred_benign).ravel()\n",
    "# print(f\"\\nBenign Detection (Class 1 + 3):\")\n",
    "# print(f\"TP (Benign correctly detected): {tp_benign}\")\n",
    "# print(f\"FP (Adversarial incorrectly detected as benign): {fp_benign}\")\n",
    "# print(f\"TN (Adversarial correctly detected): {tn_benign}\")\n",
    "# print(f\"FN (Benign missed): {fn_benign}\")\n",
    "\n",
    "# # Calculate metrics for Benign Detection\n",
    "# tpr_benign = tp_benign / (tp_benign + fn_benign) if (tp_benign + fn_benign) != 0 else 0\n",
    "# fpr_benign = fp_benign / (fp_benign + tn_benign) if (fp_benign + tn_benign) != 0 else 0\n",
    "# fnr_benign = fn_benign / (tp_benign + fn_benign) if (tp_benign + fn_benign) != 0 else 0\n",
    "# tnr_benign = tn_benign / (tn_benign + fp_benign) if (tn_benign + fp_benign) != 0 else 0  \n",
    "\n",
    "# # Calculate accuracy for Benign Detection\n",
    "# accuracy_benign = (tp_benign + tn_benign) / (tp_benign + tn_benign + fp_benign + fn_benign) if (tp_benign + tn_benign + fp_benign + fn_benign) != 0 else 0\n",
    "\n",
    "# print(f\"Benign Detection Metrics:\")\n",
    "# print(f\"Benign Detection Accuracy: {100*accuracy_benign:.2f}%\")\n",
    "# print(f\"True Positive Rate (TPR): {100*tpr_benign:.2f}%\")\n",
    "# print(f\"False Positive Rate (FPR): {100*fpr_benign:.2f}%\")\n",
    "# print(f\"False Negative Rate (FNR): {100*fnr_benign:.2f}%\")\n",
    "# print(f\"True Negative Rate (TNR): {100*tnr_benign:.2f}%\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # find intersection of benign and normal samples\n",
    "# normal_samples = np.where(y_pred_adv == 0)[0]\n",
    "# print(f\"Normal Samples: {len(normal_samples)} | {normal_samples[:5]}\")\n",
    "# normal_samples = set(normal_samples)\n",
    "# benign_samples = np.where(y_pred_benign == 1)[0]\n",
    "# print(f\"Benign Samples: {len(benign_samples)} | {benign_samples[:5]}\")\n",
    "# benign_samples = set(benign_samples)\n",
    "# intersection = normal_samples & benign_samples\n",
    "# print(f\"Intersection of Adversarial and Benign Samples: {len(intersection)}\")\n",
    "\n",
    "# # find incides from class [0, 0, 1, 0] of y_pred_indices\n",
    "# normal_indices = np.where(y_pred_indices == 2)[0]\n",
    "# print(f\"Normal Samples: {len(normal_indices)} | {normal_indices[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Manual Evaluation\n",
    "We perform the whole two-stages approach on new unseen data and evaluate the following scores:\n",
    "- Recall\n",
    "- Precision\n",
    "- Accuracy\n",
    "- F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Preprocessing data --\n",
      "--- Sampling balanced data ---\n",
      "Sample to shape: (1000, 79)\n",
      "--- Splitting labels and features ---\n",
      "--- Encoding labels as binary one-hot values ---\n",
      "--- Normalizing features using MinMaxScaler ---\n",
      "Generate Features | Indices: Index([2053501, 1417664, 1894894, 2042954, 2008688], dtype='int64')... | Shape: (1000, 70)\n",
      "Generate Labels | Indices: Index([2053501, 1417664, 1894894, 2042954, 2008688], dtype='int64')... | Shape: (1000, 2)\n",
      "BENIGN  ATTACK\n",
      "False   True      500\n",
      "True    False     500\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import functions.data_preprocessing as dp\n",
    "import importlib\n",
    "importlib.reload(dp)\n",
    "\n",
    "# exclude previously used samples\n",
    "dataset_eval_excluded = dataset.drop(index=used_indices)\n",
    "\n",
    "X_eval, y_eval, used_eval_indices = dp.preprocess_data(dataset_eval_excluded, encoding_type, normalizer, zero_columns, sample_size=500, random_sample_state=17)\n",
    "print(f\"Generate Features | Indices: {X_eval.index[:5]}... | Shape: {X_eval.shape}\")\n",
    "print(f\"Generate Labels | Indices: {y_eval.index[:5]}... | Shape: {y_eval.shape}\")\n",
    "print(y_eval.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c211e4af0b464e65959f62d0dfa7ecae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "JSMA:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial JSMA examples generated. Shape: (1000, 70)\n",
      "Create Adversarial Attack | Indices: Index([2053501, 1417664, 1894894, 2042954, 2008688], dtype='int64')... | Shape: (1000, 70)\n",
      "Accuracy: 50.00%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ATTACK     0.0000    0.0000    0.0000       500\n",
      "      BENIGN     0.5000    1.0000    0.6667       500\n",
      "\n",
      "    accuracy                         0.5000      1000\n",
      "   macro avg     0.2500    0.5000    0.3333      1000\n",
      "weighted avg     0.2500    0.5000    0.3333      1000\n",
      "\n",
      "Confusion Matrix: Positive == BENIGN\n",
      "TN: 0, FP: 500, FN: 0, TP: 500\n",
      "Predictions on Adversarial Attacks | Indices: Index([2053501, 1417664, 1894894, 2042954, 2008688], dtype='int64')... | Shape: (1000, 2)\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(ag)\n",
    "\n",
    "# X_adv_eval = ag.generate_cw_attacks_parallel(art_model, X_eval, target_label=1, num_cores=num_cores)\n",
    "# print(f\"Create Adversarial Attack | Indices: {X_adv_eval.index[:5]}... | Shape: {X_adv_eval.shape}\")\n",
    "\n",
    "X_adv_eval = ag.generate_jsma_attacks(art_model, X_eval, target_label=1)\n",
    "print(f\"Create Adversarial Attack | Indices: {X_adv_eval.index[:5]}... | Shape: {X_adv_eval.shape}\")\n",
    "\n",
    "y_pred_adv_eval = ag.evaluate_art_model(art_model, X_adv_eval, y_eval)\n",
    "print(f\"Predictions on Adversarial Attacks | Indices: {y_pred_adv_eval.index[:5]}... | Shape: {y_pred_adv_eval.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PermutationExplainer explainer: 1001it [00:39, 18.90it/s]                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Explanations | Indices: Index([2053501, 1417664, 1894894, 2042954, 2008688], dtype='int64')... | Shape: (1000, 70)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(exp)\n",
    "X_eval_adv_shap_values_df = exp.generate_shap_values(explainer, X_adv_eval)\n",
    "\n",
    "print(f\"Create Explanations | Indices: {X_eval_adv_shap_values_df.index[:5]}... | Shape: {X_eval_adv_shap_values_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # normal shap values\n",
    "\n",
    "# y_pred_adv_eval = ag.evaluate_art_model(art_model, X_eval, y_eval)\n",
    "# print(f\"Predictions on Adversarial Attacks | Indices: {y_pred_adv_eval.index[:5]}... | Shape: {y_pred_adv_eval.shape}\")\n",
    "\n",
    "# X_eval_adv_shap_values_df = exp.generate_shap_values(explainer, X_eval)\n",
    "\n",
    "# print(f\"Create Explanations | Indices: {X_eval_adv_shap_values_df.index[:5]}... | Shape: {X_eval_adv_shap_values_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 14:34:02.297606: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    }
   ],
   "source": [
    "benign_eval_idx = y_eval[y_eval['BENIGN'] == 1].index\n",
    "attack_eval_idx = y_eval[y_eval['ATTACK'] == 1].index\n",
    "\n",
    "pred_benign_idx = y_pred_adv_eval[y_pred_adv_eval['BENIGN'] == 1].index\n",
    "pred_attack_idx = y_pred_adv_eval[y_pred_adv_eval['ATTACK'] == 1].index\n",
    "\n",
    "# predict\n",
    "X_eval_detector = X_eval_adv_shap_values_df.loc[pred_benign_idx]\n",
    "y_pred_eval_detector = det.predict(detector, X_eval_detector, y_train_det.columns)\n",
    "\n",
    "# correctly_classified_det_idx = y_pred_eval_detector[y_pred_eval_detector['BENIGN'] == 1].index\n",
    "# misclassified_det_idx = y_pred_eval_detector[y_pred_eval_detector['ATTACK'] == 1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class 0: 0\n",
      "Predicted Class 1: 0\n",
      "Predicted Class 2: 0\n",
      "Predicted Class 3: 513\n",
      "Predicted Class 4: 487\n"
     ]
    }
   ],
   "source": [
    "pred_class_0 = y_pred_eval_detector[y_pred_eval_detector['ADV CORRECT BENIGN'] == 1].index \n",
    "pred_class_1 = y_pred_eval_detector[y_pred_eval_detector['ADV MISCLASSIFIED'] == 1].index\n",
    "pred_class_2 = y_pred_eval_detector[y_pred_eval_detector['CW MISCLASSIFIED'] == 1].index\n",
    "pred_class_3 = y_pred_eval_detector[y_pred_eval_detector['JSMA MISCLASSIFIED'] == 1].index\n",
    "pred_class_4 = y_pred_eval_detector[y_pred_eval_detector['CORRECT BENIGN'] == 1].index\n",
    "print(f\"Predicted Class 0: {len(pred_class_0)}\")\n",
    "print(f\"Predicted Class 1: {len(pred_class_1)}\")\n",
    "print(f\"Predicted Class 2: {len(pred_class_2)}\")\n",
    "print(f\"Predicted Class 3: {len(pred_class_3)}\")\n",
    "print(f\"Predicted Class 4: {len(pred_class_4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDS classifies 'ATTACK' samples as 'ATTACK': 0\n",
      "IDS mis-classifies 'BENIGN' samples as 'ATTACK': 0\n",
      "Detector classifies 'BENIGN' samples as correct 'BENIGN': 486\n",
      "Detector mis-classifies 'ATTACK' samples as correct 'BENIGN': 1\n",
      "Detector classifies 'ATTACK' samples as misclassified due to 'ATTACK': 499\n",
      "Detector classifies 'BENIGN' samples as misclassified due to 'ATTACK': 14\n",
      "TP: 486\n",
      "FP: 1\n",
      "TN: 499\n",
      "FN: 14\n",
      "Sum: 1000\n"
     ]
    }
   ],
   "source": [
    "# After IDS Stage\n",
    "TN = len(attack_eval_idx.intersection(pred_attack_idx)) # IDS classifies 'ATTACK' samples as 'ATTACK'\n",
    "print(f\"IDS classifies 'ATTACK' samples as 'ATTACK': {TN}\")\n",
    "FN = len(benign_eval_idx.intersection(pred_attack_idx)) # IDS classifies 'BENIGN' samples as 'ATTACK'\n",
    "print(f\"IDS mis-classifies 'BENIGN' samples as 'ATTACK': {FN}\")\n",
    "\n",
    "# TODO: define correct and misclassified classes for each attack:\n",
    "correctly_classified_det_idx = y_pred_eval_detector.loc[pred_class_4].index # Detector classifies 'BENIGN' samples as correct 'BENIGN'\n",
    "misclassified_det_idx = y_pred_eval_detector.loc[pred_class_3].index # Detector classifies 'ATTACK' samples as misclassified due to 'ATTACK'\n",
    "\n",
    "# After Detector Stage\n",
    "TP = len(benign_eval_idx.intersection(correctly_classified_det_idx)) # Detector classifies 'BENIGN' samples as correct 'BENIGN'\n",
    "print(f\"Detector classifies 'BENIGN' samples as correct 'BENIGN': {TP}\")\n",
    "FP = len(attack_eval_idx.intersection(correctly_classified_det_idx)) # Detector classifies 'ATTACK' samples as correct 'BENIGN'\n",
    "print(f\"Detector mis-classifies 'ATTACK' samples as correct 'BENIGN': {FP}\")\n",
    "\n",
    "TN_2 = len(attack_eval_idx.intersection(misclassified_det_idx)) # Detector classifies 'ATTACK' samples as misclassified due to 'ATTACK'\n",
    "print(f\"Detector classifies 'ATTACK' samples as misclassified due to 'ATTACK': {TN_2}\")\n",
    "FN_2 = len(benign_eval_idx.intersection(misclassified_det_idx)) # Detector classifies 'BENIGN' samples as misclassified due to 'ATTACK'\n",
    "print(f\"Detector classifies 'BENIGN' samples as misclassified due to 'ATTACK': {FN_2}\")\n",
    "\n",
    "# Sum up TN & FN from both stages\n",
    "TN = TN + TN_2\n",
    "FN = FN + FN_2\n",
    "\n",
    "print(f\"TP: {TP}\")\n",
    "print(f\"FP: {FP}\")\n",
    "print(f\"TN: {TN}\")\n",
    "print(f\"FN: {FN}\")\n",
    "print(f\"Sum: {TP + FP + TN + FN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Accuracy: 98.50%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ATTACK       0.97      1.00      0.99       500\n",
      "      BENIGN       1.00      0.97      0.98       500\n",
      "\n",
      "    accuracy                           0.98      1000\n",
      "   macro avg       0.99      0.98      0.98      1000\n",
      "weighted avg       0.99      0.98      0.98      1000\n",
      "\n",
      "True Negative Rate: 99.80%\n",
      "False Positive Rate: 0.20%\n",
      "True Positive Rate: 97.20%\n",
      "False Negative Rate: 2.80%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(f\"Global Accuracy: {(TP + TN) / (TP + FP + TN + FN) * 100:.2f}%\")\n",
    "\n",
    "# Construct a fake y_true and y_pred to match sklearn's classification_report format\n",
    "y_true = np.array([1] * TP + [0] * TN + [1] * FN + [0] * FP)  # True labels\n",
    "y_pred = np.array([1] * TP + [0] * TN + [0] * FN + [1] * FP)  # Predicted labels\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_true, y_pred, target_names=['ATTACK', 'BENIGN']) # reverse labels because classification_report assumes first label is 0\n",
    "print(report)\n",
    "\n",
    "print(f\"True Negative Rate: {TN/(TN+FP)*100:.2f}%\")\n",
    "print(f\"False Positive Rate: {FP/(TN+FP)*100:.2f}%\")\n",
    "print(f\"True Positive Rate: {TP/(TP+FN)*100:.2f}%\")\n",
    "print(f\"False Negative Rate: {FN/(TP+FN)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Attack-Samples: 1000\n",
      "Predicted indices: 1000\n",
      "Predicted Normal indices: 1000\n",
      "Normal Misclassified indices: 0\n",
      "ADV Detection Rate: 1.0000\n",
      "Misclassification Rate: 0.0000\n"
     ]
    }
   ],
   "source": [
    "sample_indices = y_pred_eval_detector.index\n",
    "print(f\"#Attack-Samples: {len(sample_indices)}\")\n",
    "\n",
    "detected_indices = np.unique(np.concatenate((pred_class_4, pred_class_3)))\n",
    "print(f\"Predicted indices: {len(detected_indices)}\")\n",
    "\n",
    "correct_benign_pred_indices = np.intersect1d(sample_indices, detected_indices)\n",
    "print(f\"Predicted Normal indices: {len(correct_benign_pred_indices)}\")\n",
    "\n",
    "normal_benign_misclassified_indices = np.setdiff1d(sample_indices, detected_indices)\n",
    "print(f\"Normal Misclassified indices: {len(normal_benign_misclassified_indices)}\")\n",
    "\n",
    "print(f\"ADV Detection Rate: {len(correct_benign_pred_indices) / len(sample_indices):.4f}\")\n",
    "print(f\"Misclassification Rate: {len(normal_benign_misclassified_indices) / len(sample_indices):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
