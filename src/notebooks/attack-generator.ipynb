{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Attack Generator\n",
    "\n",
    "Based on: https://github.com/Trusted-AI/adversarial-robustness-toolbox/wiki/Get-Started#setup </p>\n",
    "- Docs: https://adversarial-robustness-toolbox.readthedocs.io/en/latest/index.html\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192037, 68) (64013, 68) (192037, 2) (64013, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X_train = pd.read_csv(\"../../CICIDS2017/train_test_split/X_train_poc.csv\")\n",
    "X_test = pd.read_csv(\"../../CICIDS2017/train_test_split/X_test_poc.csv\")\n",
    "y_train = pd.read_csv(\"../../CICIDS2017/train_test_split/y_train_poc.csv\")\n",
    "y_test = pd.read_csv(\"../../CICIDS2017/train_test_split/y_test_poc.csv\")\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192037, 68) (64013, 68) (192037, 2) (64013, 2)\n",
      "(50000, 68) (2500, 68) (50000, 2) (2500, 2)\n"
     ]
    }
   ],
   "source": [
    "# POC: create smaller dataset\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "X_train = X_train.iloc[:50000]\n",
    "y_train = y_train.iloc[:50000]\n",
    "X_test = X_test.iloc[:2500]\n",
    "y_test = y_test.iloc[:2500]\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,450</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,530</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">310</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │         \u001b[38;5;34m3,450\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │         \u001b[38;5;34m1,530\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m310\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m22\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,938</span> (62.26 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,938\u001b[0m (62.26 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,312</span> (20.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,312\u001b[0m (20.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,626</span> (41.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m10,626\u001b[0m (41.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load model\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.models.load_model('../../CICIDS2017/models/ids_dnn_poc.keras')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      BENIGN       0.99      1.00      1.00     96115\n",
      "      ATTACK       1.00      0.99      1.00     95922\n",
      "\n",
      "   micro avg       1.00      1.00      1.00    192037\n",
      "   macro avg       1.00      1.00      1.00    192037\n",
      "weighted avg       1.00      1.00      1.00    192037\n",
      " samples avg       1.00      1.00      1.00    192037\n",
      "\n",
      "Accuracy : 99.64%\n"
     ]
    }
   ],
   "source": [
    "# convert model to ART -> needed for adversarial attacks\n",
    "from art.estimators.classification import TensorFlowV2Classifier\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define loss function\n",
    "loss_object = keras.losses.BinaryCrossentropy()\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "input_dim = X_train.shape[1] \n",
    "\n",
    "@tf.function\n",
    "def custom_train_step(model, x_batch, y_batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(x_batch, training=True)\n",
    "        loss = loss_object(y_batch, predictions)\n",
    "    \n",
    "    # Compute and apply gradients\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# KerasClassifier uses tf.keras.backend.placeholder, which has been removed in TensorFlow 2.10+.so we need to use TensorFlowV2Classifier\n",
    "classifier = TensorFlowV2Classifier(\n",
    "    model=model,\n",
    "    nb_classes=2,  # Binary classification (0 or 1)\n",
    "    input_shape=(input_dim,),  # Input shape\n",
    "    clip_values=(0, 1), # because of the min-max normalization\n",
    "    optimizer=optimizer, \n",
    "    loss_object=loss_object,\n",
    "    train_step=custom_train_step  # Use default training function\n",
    ")\n",
    "\n",
    "# print accuracy\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "y_pred = classifier.predict(X_train)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "print(classification_report(y_train, y_pred, target_names=['BENIGN', 'ATTACK']))\n",
    "print(f\"Accuracy : {accuracy_score(y_train, y_pred)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy -> needed for adversarial attacks\n",
    "X_test_np = X_test.to_numpy()\n",
    "X_train_np = X_train.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carlini & Wagner Attack - White Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c9b3186bb714197aaf900880c27f4f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "Adversarial C&W examples generated. Shape: (2500, 68)\n"
     ]
    }
   ],
   "source": [
    "from art.attacks.evasion import CarliniL2Method\n",
    "\n",
    "# Create the C&W attack (non-targeted)\n",
    "attack_cw = CarliniL2Method(classifier=classifier, confidence=0.0, targeted=False)\n",
    "\n",
    "# Generate adversarial examples on the test set\n",
    "X_test_adv_cw = attack_cw.generate(x=X_test_np)\n",
    "print(f'Adversarial C&W examples generated. Shape: {X_test_adv_cw.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FGSM Attack - White Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial FGSM examples generated. Shape: (50000, 68)\n"
     ]
    }
   ],
   "source": [
    "from art.attacks.evasion import FastGradientMethod\n",
    "\n",
    "# Create FGSM attack\n",
    "attack_fgsm = FastGradientMethod(estimator=classifier, eps=0.1)  # ε tune this for stronger/weaker attacks: 0.01 weak, 0.1 balanced, 0.3-0.5 strong, 1 very strong\n",
    "# the higher the epsilon, the easier it will be detected\n",
    "\n",
    "# Generate adversarial examples\n",
    "X_train_adv_fgsm = attack_fgsm.generate(x=X_train_np)\n",
    "print(f'Adversarial FGSM examples generated. Shape: {X_train_adv_fgsm.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HopSkipJumpAttack - Black Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "307a6674b2ea48a29ff756e317686080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HopSkipJump:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial HopSkipJump examples generated. Shape: (2000, 70)\n"
     ]
    }
   ],
   "source": [
    "from art.attacks.evasion import HopSkipJump\n",
    "import numpy as np\n",
    "\n",
    "# Create HopSkipJump attack\n",
    "attack_hop_skip_jump = HopSkipJump(classifier=classifier, targeted=False, norm=2)\n",
    "\n",
    "# Generate adversarial examples\n",
    "X_test_adv_hop_skip_jump = attack_hop_skip_jump.generate(x=X_test_np)\n",
    "print(f'Adversarial HopSkipJump examples generated. Shape: {X_test_adv_hop_skip_jump.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# check for negative values in attacks\n",
    "print(np.any(X_test_adv_cw < 0))\n",
    "print(np.any(X_train_adv_fgsm < 0))\n",
    "print(np.any(X_test_adv_hop_skip_jump < 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9974 - loss: 0.0064\n",
      "Accuracy on clean examples: 99.72%\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2759 - loss: 47.7132\n",
      "Accuracy on fgsm attack: 27.77%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on adversarial examples\n",
    "loss, accuracy = model.evaluate(X_test_np, y_test)\n",
    "print(f'Accuracy on clean examples: {accuracy * 100:.2f}%')\n",
    "\n",
    "# loss_adv, accuracy_adv = model.evaluate(X_test_adv_cw, y_test)\n",
    "# print(f'Accuracy on C&W attack: {accuracy_adv * 100:.2f}%')\n",
    "\n",
    "loss_adv_fgsm, accuracy_adv_fgsm = model.evaluate(X_train_adv_fgsm, y_train)\n",
    "print(f'Accuracy on fgsm attack: {accuracy_adv_fgsm * 100:.2f}%')\n",
    "\n",
    "# loss_adv_hop_skip_jump, accuracy_adv_hop_skip_jump = model.evaluate(X_test_adv_hop_skip_jump, y_test)\n",
    "# print(f'Accuracy on hop skip jump attack: {accuracy_adv_hop_skip_jump * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step\n",
      "Normal Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      BENIGN       0.99      1.00      1.00      1260\n",
      "      ATTACK       1.00      0.99      1.00      1240\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      2500\n",
      "   macro avg       1.00      1.00      1.00      2500\n",
      "weighted avg       1.00      1.00      1.00      2500\n",
      " samples avg       1.00      1.00      1.00      2500\n",
      "\n",
      "C&W Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      BENIGN       0.74      0.97      0.84      1260\n",
      "      ATTACK       0.96      0.65      0.78      1240\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      2500\n",
      "   macro avg       0.85      0.81      0.81      2500\n",
      "weighted avg       0.85      0.82      0.81      2500\n",
      " samples avg       0.82      0.82      0.82      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "y_pred_adv_cw = model.predict(X_test_adv_cw)\n",
    "y_pred_adv_cw = (y_pred_adv_cw > 0.5)\n",
    "# y_pred_adv_fgsm = model.predict(X_test_adv_fgsm)\n",
    "# y_pred_adv_fgsm = (y_pred_adv_fgsm > 0.5)\n",
    "# y_pred_adv_hop_skip_jump = model.predict(X_test_adv_hop_skip_jump)\n",
    "# y_pred_adv_hop_skip_jump = (y_pred_adv_hop_skip_jump > 0.5)\n",
    "\n",
    "print(\"Normal Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['BENIGN', 'ATTACK']))\n",
    "print(\"C&W Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_adv_cw, target_names=['BENIGN', 'ATTACK']))\n",
    "# print(\"FGSM Classification Report:\")\n",
    "# print(classification_report(y_test, y_pred_adv_fgsm, target_names=['BENIGN', 'ATTACK']))\n",
    "# print(\"Hop Skip Jump Classification Report:\")\n",
    "# print(classification_report(y_test, y_pred_adv_hop_skip_jump, target_names=['BENIGN', 'ATTACK']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Confusion Matrix:\n",
      "TN: 812, FP: 428, FN: 33, TP: 1227\n",
      "Normal:\n",
      "Accuracy: 99.72%\n",
      "Precision: 99.45%\n",
      "Recall: 100.00%\n",
      "F1-Score: 99.72%\n",
      "C&W:\n",
      "Accuracy: 81.56%\n",
      "Precision: 74.14%\n",
      "Recall: 97.38%\n",
      "F1-Score: 84.19%\n"
     ]
    }
   ],
   "source": [
    "# show accuracy, precision, recall, f1-score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# convert to binary \n",
    "y_test_binary = np.array(y_test).argmin(axis=1)\n",
    "y_pred_binary = np.array(y_pred).argmin(axis=1)\n",
    "y_pred_adv_cw_binary = np.array(y_pred_adv_cw).argmin(axis=1)\n",
    "# y_pred_adv_fgsm_binary = np.array(y_pred_adv_fgsm).argmin(axis=1)\n",
    "# y_pred_adv_hop_skip_jump_binary = np.array(y_pred_adv_hop_skip_jump).argmin(axis=1)\n",
    "\n",
    "print(\"Normal:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_binary, y_pred_binary)*100:.2f}%\")\n",
    "print(f\"Precision: {precision_score(y_test_binary, y_pred_binary)*100:.2f}%\")\n",
    "print(f\"Recall: {recall_score(y_test_binary, y_pred_binary)*100:.2f}%\")\n",
    "print(f\"F1-Score: {f1_score(y_test_binary, y_pred_binary)*100:.2f}%\")\n",
    "\n",
    "print(\"C&W:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_binary, y_pred_adv_cw_binary)*100:.2f}%\")\n",
    "print(f\"Precision: {precision_score(y_test_binary, y_pred_adv_cw_binary)*100:.2f}%\")\n",
    "print(f\"Recall: {recall_score(y_test_binary, y_pred_adv_cw_binary)*100:.2f}%\")\n",
    "print(f\"F1-Score: {f1_score(y_test_binary, y_pred_adv_cw_binary)*100:.2f}%\")\n",
    "\n",
    "# print(\"FGSM:\")\n",
    "# print(f\"Accuracy: {accuracy_score(y_test_binary, y_pred_adv_fgsm_binary)*100:.2f}%\")\n",
    "# print(f\"Precision: {precision_score(y_test_binary, y_pred_adv_fgsm_binary)*100:.2f}%\")\n",
    "# print(f\"Recall: {recall_score(y_test_binary, y_pred_adv_fgsm_binary)*100:.2f}%\")\n",
    "# print(f\"F1-Score: {f1_score(y_test_binary, y_pred_adv_fgsm_binary)*100:.2f}%\")\n",
    "\n",
    "# print(\"Hop Skip Jump:\")\n",
    "# print(f\"Accuracy: {accuracy_score(y_test_binary, y_pred_adv_hop_skip_jump_binary)*100:.2f}%\")\n",
    "# print(f\"Precision: {precision_score(y_test_binary, y_pred_adv_hop_skip_jump_binary)*100:.2f}%\")\n",
    "# print(f\"Recall: {recall_score(y_test_binary, y_pred_adv_hop_skip_jump_binary)*100:.2f}%\")\n",
    "# print(f\"F1-Score: {f1_score(y_test_binary, y_pred_adv_hop_skip_jump_binary)*100:.2f}%\")\n",
    "\n",
    "# print tp, tn, fp, fn\n",
    "print(\"Confusion Matrix - C&W Attack:\")\n",
    "tn, fp, fn, tp = confusion_matrix(y_test_binary, y_pred_adv_cw_binary).ravel()\n",
    "print(f\"TN: {tn}, FP: {fp}, FN: {fn}, TP: {tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Adversarial Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv_cw_df = pd.DataFrame(X_test_adv_cw)\n",
    "# # set column names\n",
    "# adv_cw_df.columns = X_test.columns\n",
    "\n",
    "adv_fgsm_df = pd.DataFrame(X_train_adv_fgsm)\n",
    "# set column names\n",
    "adv_fgsm_df.columns = X_train.columns\n",
    "\n",
    "# adv_hop_skip_jump_df = pd.DataFrame(X_test_adv_hop_skip_jump)\n",
    "# # set column names\n",
    "# adv_hop_skip_jump_df.columns = X_test.columns\n",
    "\n",
    "norm_df = pd.DataFrame(X_test_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the adversarial examples\n",
    "# adv_cw_df.to_csv(\"../../CICIDS2017/adversarial_samples/X_test_adv_cw_poc.csv\", index=False)\n",
    "adv_fgsm_df.to_csv(\"../../CICIDS2017/adversarial_samples/X_train_adv_fgsm_poc_50000.csv\", index=False)\n",
    "# adv_hop_skip_jump_df.to_csv(\"../../CICIDS2017/adversarial_samples/X_test_adv_hsj_proto.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Destination Port   Flow Duration   Total Fwd Packets  \\\n",
      "0           0.501221        0.528566                 0.0   \n",
      "1           0.302768        0.000000                 0.5   \n",
      "\n",
      "    Total Backward Packets  Total Length of Fwd Packets  \\\n",
      "0                      0.5                     0.500129   \n",
      "1                      0.0                     0.000000   \n",
      "\n",
      "    Total Length of Bwd Packets   Fwd Packet Length Max  \\\n",
      "0                           0.5                0.500431   \n",
      "1                           0.0                0.000000   \n",
      "\n",
      "    Fwd Packet Length Min   Fwd Packet Length Mean   Fwd Packet Length Std  \\\n",
      "0                0.504076                 0.501552                     0.5   \n",
      "1                0.000000                 0.000000                     0.0   \n",
      "\n",
      "   ...   act_data_pkt_fwd   min_seg_size_forward  Active Mean   Active Std  \\\n",
      "0  ...                0.0               0.884615          0.5          0.5   \n",
      "1  ...                0.5               0.115385          0.0          0.0   \n",
      "\n",
      "    Active Max   Active Min  Idle Mean   Idle Std   Idle Max   Idle Min  \n",
      "0          0.5          0.5        0.0        0.0        0.0        0.0  \n",
      "1          0.0          0.0        0.5        0.5        0.5        0.5  \n",
      "\n",
      "[2 rows x 68 columns]\n",
      "         0             1         2        3         4    5         6   \\\n",
      "0  0.001221  2.856595e-02  0.002071  0.00000  0.000129  0.0  0.000431   \n",
      "1  0.802768  5.333336e-07  0.000000  0.00034  0.000000  0.0  0.000000   \n",
      "\n",
      "         7         8    9   ...        58        59   60   61   62   63   64  \\\n",
      "0  0.004076  0.001552  0.0  ...  0.002071  0.384615  0.0  0.0  0.0  0.0  0.0   \n",
      "1  0.000000  0.000000  0.0  ...  0.000000  0.615385  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "    65   66   67  \n",
      "0  0.0  0.0  0.0  \n",
      "1  0.0  0.0  0.0  \n",
      "\n",
      "[2 rows x 68 columns]\n"
     ]
    }
   ],
   "source": [
    "#print(adv_cw_df.head(2))\n",
    "print(adv_fgsm_df.head(2))\n",
    "# print(adv_hop_skip_jump_df.head(2))\n",
    "print(norm_df.head(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
